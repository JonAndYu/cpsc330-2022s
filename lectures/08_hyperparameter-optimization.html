
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Lecture 8: Hyperparameter Optimization and Optimization Bias &#8212; CPSC 330 Applied Machine Learning</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Lecture 9: Classification Metrics" href="09_classification-metrics.html" />
    <link rel="prev" title="Lecture 7: Linear Models" href="07_linear-models.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/UBC-CS-logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">CPSC 330 Applied Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Things you should know
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../docs/README.html">
   CPSC 330 Documents
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Lectures
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_intro.html">
   Lecture 1: Course Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_decision-trees.html">
   Lecture 2: Terminology, Baselines, Decision Trees
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_ml-fundamentals.html">
   Lecture 3: Machine Learning Fundamentals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_kNNs-SVM-RBF.html">
   Lecture 4:
   <span class="math notranslate nohighlight">
    \(k\)
   </span>
   -Nearest Neighbours and SVM RBFs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05_preprocessing-pipelines.html">
   Lecture 5: Preprocessing and
   <code class="docutils literal notranslate">
    <span class="pre">
     sklearn
    </span>
   </code>
   pipelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06_column-transformer-text-feats.html">
   Lecture 6:
   <code class="docutils literal notranslate">
    <span class="pre">
     sklearn
    </span>
   </code>
   <code class="docutils literal notranslate">
    <span class="pre">
     ColumnTransformer
    </span>
   </code>
   and Text Features
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07_linear-models.html">
   Lecture 7: Linear Models
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Lecture 8: Hyperparameter Optimization and Optimization Bias
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="09_classification-metrics.html">
   Lecture 9: Classification Metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="10_regression-metrics.html">
   Lecture 10: Regression Evaluation Metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="11_ensembles.html">
   Lecture 11: Ensembles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="12_feat-importances.html">
   Lecture 12: Feature importances
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="13_feature-engineering-selection.html">
   Lecture 13: Feature engineering and feature selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="14_k-means-clustering.html">
   Lecture 14: Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="15_recommender-systems.html">
   Lecture 15: DBSCAN and Recommender Systems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="16_natural-language-processing.html">
   Lecture 16: Introduction to natural language processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="17_intro_to_computer-vision.html">
   Lecture 17: Multi-class classification and introduction to computer vision
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="18_time-series.html">
   Lecture 18: Time series
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="19_survival-analysis.html">
   Lecture 19: Survival analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="20_ethics.html">
   Lecture 20: Ethics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="21_communication.html">
   Lecture 21: Communication
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="22_deployment-conclusion.html">
   Lecture 22: Deployment and conclusion
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Attribution
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../attribution.html">
   Attributions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../LICENSE.html">
   LICENSE
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Varada Kolhatkar, CPSC 330 2021-22<br>Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/lectures/08_hyperparameter-optimization.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/UBC-CS/cpsc330/master?urlpath=tree/lectures/08_hyperparameter-optimization.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imports">
   Imports
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lecture-plan-for-today">
   Lecture plan for today
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#announcements">
   Announcements
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#learning-outcomes">
     Learning outcomes
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hyperparameter-optimization-motivation">
   Hyperparameter optimization motivation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#motivation">
     Motivation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hyperparameters-the-problem">
     Hyperparameters: the problem
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#some-ways-to-pick-hyperparameters">
     Some ways to pick hyperparameters:
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#manual-hyperparameter-optimization">
       Manual hyperparameter optimization
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#automated-hyperparameter-optimization">
     Automated hyperparameter optimization
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exhaustive-grid-search-sklearn-model-selection-gridsearchcv">
   Exhaustive grid search:
   <code class="docutils literal notranslate">
    <span class="pre">
     sklearn.model_selection.GridSearchCV
    </span>
   </code>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#n-jobs-1">
     <code class="docutils literal notranslate">
      <span class="pre">
       n_jobs=-1
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-syntax">
     The
     <code class="docutils literal notranslate">
      <span class="pre">
       __
      </span>
     </code>
     syntax
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualizing-the-parameter-grid-as-a-heatmap">
     Visualizing the parameter grid as a heatmap
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bad-range-for-hyperparameters">
     Bad range for hyperparameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#different-range-for-hyperparameters-yields-better-results">
     Different range for hyperparameters yields better results!
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#true-false">
     True/False
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#problems-with-exhaustive-grid-search">
     Problems with exhaustive grid search
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#randomized-hyperparameter-search">
   Randomized hyperparameter search
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#n-iter">
     <code class="docutils literal notranslate">
      <span class="pre">
       n_iter
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#range-of-c">
     Range of
     <code class="docutils literal notranslate">
      <span class="pre">
       C
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#advantages-of-randomizedsearchcv">
     Advantages of
     <code class="docutils literal notranslate">
      <span class="pre">
       RandomizedSearchCV
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Advantages of
     <code class="docutils literal notranslate">
      <span class="pre">
       RandomizedSearchCV
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fancier-methods-optional">
   Fancier methods (optional)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#questions-for-class-discussion-hyperparameter-optimization">
     Questions for class discussion (hyperparameter optimization)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimization-bias-overfitting-of-the-validation-set">
   Optimization bias/Overfitting of the validation set
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overfitting-of-the-validation-error">
     Overfitting of the validation error
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimization-bias-of-parameter-learning">
     Optimization bias of parameter learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimization-bias-of-hyper-parameter-learning">
     Optimization bias of hyper-parameter learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-1-optimization-bias-optional">
     Example 1: Optimization bias (optional)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-2-optimization-bias-optional">
     Example 2: Optimization bias (optional)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimization-bias-on-the-spotify-dataset">
     Optimization bias on the Spotify dataset
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overfitting-of-the-validation-data">
     Overfitting of the validation data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-do-we-need-a-test-set">
     Why do we need a test set?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#when-test-score-is-much-lower-than-cv-score">
     When test score is much lower than CV score
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#large-datasets-solve-many-of-these-problems">
     Large datasets solve many of these problems
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#questions-for-you">
     ❓❓ Questions for you
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#would-you-trust-the-model">
     Would you trust the model?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Would you trust the model?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     Would you trust the model?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#final-comments-and-summary">
   Final comments and summary
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     Automated hyperparameter optimization
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optional-readings-and-resources">
   Optional readings and resources
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Lecture 8: Hyperparameter Optimization and Optimization Bias</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imports">
   Imports
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lecture-plan-for-today">
   Lecture plan for today
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#announcements">
   Announcements
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#learning-outcomes">
     Learning outcomes
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hyperparameter-optimization-motivation">
   Hyperparameter optimization motivation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#motivation">
     Motivation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hyperparameters-the-problem">
     Hyperparameters: the problem
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#some-ways-to-pick-hyperparameters">
     Some ways to pick hyperparameters:
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#manual-hyperparameter-optimization">
       Manual hyperparameter optimization
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#automated-hyperparameter-optimization">
     Automated hyperparameter optimization
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exhaustive-grid-search-sklearn-model-selection-gridsearchcv">
   Exhaustive grid search:
   <code class="docutils literal notranslate">
    <span class="pre">
     sklearn.model_selection.GridSearchCV
    </span>
   </code>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#n-jobs-1">
     <code class="docutils literal notranslate">
      <span class="pre">
       n_jobs=-1
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-syntax">
     The
     <code class="docutils literal notranslate">
      <span class="pre">
       __
      </span>
     </code>
     syntax
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualizing-the-parameter-grid-as-a-heatmap">
     Visualizing the parameter grid as a heatmap
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bad-range-for-hyperparameters">
     Bad range for hyperparameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#different-range-for-hyperparameters-yields-better-results">
     Different range for hyperparameters yields better results!
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#true-false">
     True/False
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#problems-with-exhaustive-grid-search">
     Problems with exhaustive grid search
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#randomized-hyperparameter-search">
   Randomized hyperparameter search
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#n-iter">
     <code class="docutils literal notranslate">
      <span class="pre">
       n_iter
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#range-of-c">
     Range of
     <code class="docutils literal notranslate">
      <span class="pre">
       C
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#advantages-of-randomizedsearchcv">
     Advantages of
     <code class="docutils literal notranslate">
      <span class="pre">
       RandomizedSearchCV
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Advantages of
     <code class="docutils literal notranslate">
      <span class="pre">
       RandomizedSearchCV
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fancier-methods-optional">
   Fancier methods (optional)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#questions-for-class-discussion-hyperparameter-optimization">
     Questions for class discussion (hyperparameter optimization)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimization-bias-overfitting-of-the-validation-set">
   Optimization bias/Overfitting of the validation set
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overfitting-of-the-validation-error">
     Overfitting of the validation error
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimization-bias-of-parameter-learning">
     Optimization bias of parameter learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimization-bias-of-hyper-parameter-learning">
     Optimization bias of hyper-parameter learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-1-optimization-bias-optional">
     Example 1: Optimization bias (optional)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-2-optimization-bias-optional">
     Example 2: Optimization bias (optional)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimization-bias-on-the-spotify-dataset">
     Optimization bias on the Spotify dataset
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overfitting-of-the-validation-data">
     Overfitting of the validation data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-do-we-need-a-test-set">
     Why do we need a test set?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#when-test-score-is-much-lower-than-cv-score">
     When test score is much lower than CV score
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#large-datasets-solve-many-of-these-problems">
     Large datasets solve many of these problems
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#questions-for-you">
     ❓❓ Questions for you
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#would-you-trust-the-model">
     Would you trust the model?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Would you trust the model?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     Would you trust the model?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#final-comments-and-summary">
   Final comments and summary
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     Automated hyperparameter optimization
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optional-readings-and-resources">
   Optional readings and resources
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <p><img alt="" src="../_images/330-banner.png" /></p>
<div class="tex2jax_ignore mathjax_ignore section" id="lecture-8-hyperparameter-optimization-and-optimization-bias">
<h1>Lecture 8: Hyperparameter Optimization and Optimization Bias<a class="headerlink" href="#lecture-8-hyperparameter-optimization-and-optimization-bias" title="Permalink to this headline">¶</a></h1>
<p>UBC 2020-21</p>
<p>Instructor: Varada Kolhatkar</p>
<div class="section" id="imports">
<h2>Imports<a class="headerlink" href="#imports" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;code/.&quot;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">IPython</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">mglearn</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span><span class="p">,</span> <span class="n">display</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">interactive</span>
<span class="kn">from</span> <span class="nn">plotting_functions</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span><span class="p">,</span> <span class="n">TfidfVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">cross_validate</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span><span class="p">,</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s2">&quot;display.max_colwidth&quot;</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="lecture-plan-for-today">
<h2>Lecture plan for today<a class="headerlink" href="#lecture-plan-for-today" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Announcements (~2 mins)</p></li>
<li><p>Watch hyperparameter optimization video on your own: https://youtu.be/lMWdHZSZMk8</p></li>
<li><p>Live lecturing on <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> and <code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code>.</p></li>
<li><p>Q&amp;A and exercises</p></li>
<li><p>Break</p></li>
<li><p>Watch optimization bias video on your own: https://youtu.be/Z9a9XZ0vQv0</p></li>
<li><p>Q&amp;A and exercises</p></li>
</ul>
<p><br><br></p>
</div>
<div class="section" id="announcements">
<h2>Announcements<a class="headerlink" href="#announcements" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>HW4 deadline extension (due on Friday, October 15, 11:59pm)</p></li>
<li><p>HW3 solutions have been released</p></li>
<li><p>HW3 grading in progress</p></li>
</ul>
<div class="section" id="learning-outcomes">
<h3>Learning outcomes<a class="headerlink" href="#learning-outcomes" title="Permalink to this headline">¶</a></h3>
<p>From this lecture, you will be able to</p>
<ul class="simple">
<li><p>explain the need for hyperparameter optimization</p></li>
<li><p>carry out hyperparameter optimization using <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>’s <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> and <code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code></p></li>
<li><p>explain different hyperparameters of <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code></p></li>
<li><p>explain the importance of selecting a good range for the values.</p></li>
<li><p>explain optimization bias</p></li>
<li><p>identify and reason when to trust and not trust reported accuracies</p></li>
</ul>
<p><br><br><br><br></p>
</div>
</div>
<div class="section" id="hyperparameter-optimization-motivation">
<h2>Hyperparameter optimization motivation<a class="headerlink" href="#hyperparameter-optimization-motivation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="motivation">
<h3>Motivation<a class="headerlink" href="#motivation" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Remember that the fundamental goal of supervised machine learning is to generalize beyond what we see in the training examples.</p></li>
<li><p>We have been using data splitting and cross-validation to provide a framework to approximate generalization error.</p></li>
<li><p>With this framework, we can improve the model’s generalization performance by tuning model hyperparameters using cross-validation on the training set.</p></li>
</ul>
</div>
<div class="section" id="hyperparameters-the-problem">
<h3>Hyperparameters: the problem<a class="headerlink" href="#hyperparameters-the-problem" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>In order to improve the generalization performance, finding the best values for the important hyperparameters of a model is necessary for almost all models and datasets.</p></li>
<li><p>Picking good hyperparameters is important because if we don’t do it, we might end up with an underfit or overfit model.</p></li>
</ul>
</div>
<div class="section" id="some-ways-to-pick-hyperparameters">
<h3>Some ways to pick hyperparameters:<a class="headerlink" href="#some-ways-to-pick-hyperparameters" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Manual or expert knowledge or heuristics based optimization</p></li>
<li><p>Data-driven or automated optimization</p></li>
</ul>
<div class="section" id="manual-hyperparameter-optimization">
<h4>Manual hyperparameter optimization<a class="headerlink" href="#manual-hyperparameter-optimization" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>Advantage: we may have some intuition about what might work.</p>
<ul>
<li><p>E.g. if I’m massively overfitting, try decreasing <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> or <code class="docutils literal notranslate"><span class="pre">C</span></code>.</p></li>
</ul>
</li>
<li><p>Disadvantages</p>
<ul>
<li><p>it takes a lot of work</p></li>
<li><p>not reproducible</p></li>
<li><p>in very complicated cases, our intuition might be worse than a data-driven approach</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="automated-hyperparameter-optimization">
<h3>Automated hyperparameter optimization<a class="headerlink" href="#automated-hyperparameter-optimization" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Formulate the hyperparamter optimization as a one big search problem.</p></li>
<li><p>Often we have many hyperparameters of different types: Categorical, integer, and continuous.</p></li>
<li><p>Often, the search space is quite big and systematic search for optimal values is infeasible.</p></li>
</ul>
<p>In homework assignments, we have been carrying out hyperparameter search by exhaustively trying different possible combinations of the hyperparameters of interest.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_grid_search_overview</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/08_hyperparameter-optimization_16_0.png" src="../_images/08_hyperparameter-optimization_16_0.png" />
</div>
</div>
<p>Let’s look at an example of tuning <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> of the <code class="docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code> on the Spotify dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">spotify_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/spotify.csv&quot;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_spotify</span> <span class="o">=</span> <span class="n">spotify_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">,</span> <span class="s2">&quot;song_title&quot;</span><span class="p">,</span> <span class="s2">&quot;artist&quot;</span><span class="p">])</span>
<span class="n">y_spotify</span> <span class="o">=</span> <span class="n">spotify_df</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span>
<span class="n">X_spotify</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>acousticness</th>
      <th>danceability</th>
      <th>duration_ms</th>
      <th>energy</th>
      <th>instrumentalness</th>
      <th>key</th>
      <th>liveness</th>
      <th>loudness</th>
      <th>mode</th>
      <th>speechiness</th>
      <th>tempo</th>
      <th>time_signature</th>
      <th>valence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0102</td>
      <td>0.833</td>
      <td>204600</td>
      <td>0.434</td>
      <td>0.021900</td>
      <td>2</td>
      <td>0.1650</td>
      <td>-8.795</td>
      <td>1</td>
      <td>0.4310</td>
      <td>150.062</td>
      <td>4.0</td>
      <td>0.286</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.1990</td>
      <td>0.743</td>
      <td>326933</td>
      <td>0.359</td>
      <td>0.006110</td>
      <td>1</td>
      <td>0.1370</td>
      <td>-10.401</td>
      <td>1</td>
      <td>0.0794</td>
      <td>160.083</td>
      <td>4.0</td>
      <td>0.588</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0344</td>
      <td>0.838</td>
      <td>185707</td>
      <td>0.412</td>
      <td>0.000234</td>
      <td>2</td>
      <td>0.1590</td>
      <td>-7.148</td>
      <td>1</td>
      <td>0.2890</td>
      <td>75.044</td>
      <td>4.0</td>
      <td>0.173</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.6040</td>
      <td>0.494</td>
      <td>199413</td>
      <td>0.338</td>
      <td>0.510000</td>
      <td>5</td>
      <td>0.0922</td>
      <td>-15.236</td>
      <td>1</td>
      <td>0.0261</td>
      <td>86.468</td>
      <td>4.0</td>
      <td>0.230</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.1800</td>
      <td>0.678</td>
      <td>392893</td>
      <td>0.561</td>
      <td>0.512000</td>
      <td>5</td>
      <td>0.4390</td>
      <td>-11.648</td>
      <td>0</td>
      <td>0.0694</td>
      <td>174.004</td>
      <td>4.0</td>
      <td>0.904</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_spotify</span><span class="p">,</span> <span class="n">y_spotify</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_score</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)}</span>

<span class="n">results_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;mean_cv_score&quot;</span><span class="p">:</span> <span class="p">[]}</span>

<span class="k">for</span> <span class="n">depth</span> <span class="ow">in</span> <span class="n">param_grid</span><span class="p">[</span>
    <span class="s2">&quot;max_depth&quot;</span>
<span class="p">]:</span>  <span class="c1"># for each combination of parameters, train an SVC</span>
    <span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">depth</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>  <span class="c1"># perform cross-validation</span>
    <span class="n">mean_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>  <span class="c1"># compute mean cross-validation accuracy</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="n">mean_score</span> <span class="o">&gt;</span> <span class="n">best_score</span>
    <span class="p">):</span>  <span class="c1"># if we got a better score, store the score and parameters</span>
        <span class="n">best_score</span> <span class="o">=</span> <span class="n">mean_score</span>
        <span class="n">best_params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="n">depth</span><span class="p">}</span>
    <span class="n">results_dict</span><span class="p">[</span><span class="s2">&quot;max_depth&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">depth</span><span class="p">)</span>
    <span class="n">results_dict</span><span class="p">[</span><span class="s2">&quot;mean_cv_score&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_score</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_params</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;max_depth&#39;: 5}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_score</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7210237870892063
</pre></div>
</div>
</div>
</div>
<p>Let’s try SVM RBF and tuning <code class="docutils literal notranslate"><span class="pre">C</span></code> and <code class="docutils literal notranslate"><span class="pre">gamma</span></code> on the same dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_svm</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">SVC</span><span class="p">())</span>  <span class="c1"># We need scaling for SVM RBF</span>
<span class="n">pipe_svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pipeline(steps=[(&#39;standardscaler&#39;, StandardScaler()), (&#39;svc&#39;, SVC())])
</pre></div>
</div>
</div>
</div>
<p>Let’s try cross-validation with default hyperparameters of SVC.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">pipe_svm</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       0.072955
score_time     0.039258
test_score     0.738998
train_score    0.814011
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Now let’s try exhaustive hyperparameter search using for loops.</p>
<p>This is what we have been doing for this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">gamma</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span> <span class="c1"># for some values of gamma</span>
    <span class="k">for</span> <span class="n">C</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span> <span class="c1"># for some values of C</span>
        <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">folds</span><span class="p">:</span>
            <span class="n">fit</span> <span class="ow">in</span> <span class="n">training</span> <span class="n">portion</span> <span class="k">with</span> <span class="n">the</span> <span class="n">given</span> <span class="n">C</span>
            <span class="n">score</span> <span class="n">on</span> <span class="n">validation</span> <span class="n">portion</span>
        <span class="n">compute</span> <span class="n">average</span> <span class="n">score</span>
        
<span class="n">pick</span> <span class="n">hyperparameter</span> <span class="n">values</span> <span class="n">which</span> <span class="k">yield</span> <span class="k">with</span> <span class="n">best</span> <span class="n">average</span> <span class="n">score</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_score</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;C&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
    <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">results_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;C&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;mean_cv_score&quot;</span><span class="p">:</span> <span class="p">[]}</span>

<span class="k">for</span> <span class="n">gamma</span> <span class="ow">in</span> <span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;gamma&quot;</span><span class="p">]:</span>
    <span class="k">for</span> <span class="n">C</span> <span class="ow">in</span> <span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;C&quot;</span><span class="p">]:</span>  <span class="c1"># for each combination of parameters, train an SVC</span>
        <span class="n">pipe_svm</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">))</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">pipe_svm</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>  <span class="c1"># perform cross-validation</span>
        <span class="n">mean_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>  <span class="c1"># compute mean cross-validation accuracy</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">mean_score</span> <span class="o">&gt;</span> <span class="n">best_score</span>
        <span class="p">):</span>  <span class="c1"># if we got a better score, store the score and parameters</span>
            <span class="n">best_score</span> <span class="o">=</span> <span class="n">mean_score</span>
            <span class="n">best_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;C&quot;</span><span class="p">:</span> <span class="n">C</span><span class="p">,</span> <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="n">gamma</span><span class="p">}</span>
        <span class="n">results_dict</span><span class="p">[</span><span class="s2">&quot;C&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
        <span class="n">results_dict</span><span class="p">[</span><span class="s2">&quot;gamma&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gamma</span><span class="p">)</span>
        <span class="n">results_dict</span><span class="p">[</span><span class="s2">&quot;mean_cv_score&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_score</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_parameters</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;C&#39;: 1, &#39;gamma&#39;: 0.1}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_score</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7439609253312309
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results_dict</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;mean_cv_score&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>C</th>
      <th>gamma</th>
      <th>mean_cv_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>15</th>
      <td>1.0</td>
      <td>0.100</td>
      <td>0.743961</td>
    </tr>
    <tr>
      <th>11</th>
      <td>100.0</td>
      <td>0.010</td>
      <td>0.732792</td>
    </tr>
    <tr>
      <th>16</th>
      <td>10.0</td>
      <td>0.100</td>
      <td>0.729091</td>
    </tr>
    <tr>
      <th>10</th>
      <td>10.0</td>
      <td>0.010</td>
      <td>0.720391</td>
    </tr>
    <tr>
      <th>17</th>
      <td>100.0</td>
      <td>0.100</td>
      <td>0.711715</td>
    </tr>
    <tr>
      <th>5</th>
      <td>100.0</td>
      <td>0.001</td>
      <td>0.704284</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.1</td>
      <td>0.100</td>
      <td>0.703034</td>
    </tr>
    <tr>
      <th>9</th>
      <td>1.0</td>
      <td>0.010</td>
      <td>0.697473</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.1</td>
      <td>0.010</td>
      <td>0.678851</td>
    </tr>
    <tr>
      <th>4</th>
      <td>10.0</td>
      <td>0.001</td>
      <td>0.678244</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">mean_cv_score</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>

<span class="n">mglearn</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span>
    <span class="n">scores</span><span class="p">,</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">,</span>
    <span class="n">xticklabels</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;C&quot;</span><span class="p">],</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;gamma&quot;</span><span class="p">,</span>
    <span class="n">yticklabels</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;gamma&quot;</span><span class="p">],</span>
    <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;viridis&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># plot the mean cross-validation scores</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.collections.PolyCollection at 0x12ed1db50&gt;
</pre></div>
</div>
<img alt="../_images/08_hyperparameter-optimization_33_1.png" src="../_images/08_hyperparameter-optimization_33_1.png" />
</div>
</div>
<ul class="simple">
<li><p>We have 6 possible values for <code class="docutils literal notranslate"><span class="pre">C</span></code> and 6 possible values for <code class="docutils literal notranslate"><span class="pre">gamma</span></code>.</p></li>
<li><p>In 5-fold cross-validation, for each combination of parameter values, five accuracies are computed.</p></li>
<li><p>So to evaluate the accuracy of the SVM using 6 values of <code class="docutils literal notranslate"><span class="pre">C</span></code> and 6 values of <code class="docutils literal notranslate"><span class="pre">gamma</span></code> using five-fold cross-validation, we need to train 36 * 5 = 180 models!</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">len</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">.</span><span class="n">values</span><span class="p">())))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>36
</pre></div>
</div>
</div>
</div>
<p>Once we have optimized hyperparameters, we retrain a model on the full training set with these optimized hyperparameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_svm</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">SVC</span><span class="p">(</span><span class="o">**</span><span class="n">best_parameters</span><span class="p">))</span>
<span class="n">pipe_svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span>
<span class="p">)</span>  <span class="c1"># Retrain a model with optimized hyperparameters on the combined training and validation set</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pipeline(steps=[(&#39;standardscaler&#39;, StandardScaler()),
                (&#39;svc&#39;, SVC(C=1, gamma=0.1))])
</pre></div>
</div>
</div>
</div>
<p>And finally evaluate the performance of this model on the test set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_svm</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>  <span class="c1"># Final evaluation on the test data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7376237623762376
</pre></div>
</div>
</div>
</div>
<p>This process is so common that there are some standard methods in <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> where we can carry out all of this in a more compact way.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_grid_search_overview</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/08_hyperparameter-optimization_41_0.png" src="../_images/08_hyperparameter-optimization_41_0.png" />
</div>
</div>
<p>In this lecture we are going to talk about two such most commonly used automated optimizations methods from <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>.</p>
<ul class="simple">
<li><p>Exhaustive grid search: <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"><code class="docutils literal notranslate"><span class="pre">sklearn.model_selection.GridSearchCV</span></code></a></p></li>
<li><p>Randomized search: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html"><code class="docutils literal notranslate"><span class="pre">sklearn.model_selection.RandomizedSearchCV</span></code></a></p></li>
</ul>
<p>The “CV” stands for cross-validation; these methods have built-in cross-validation.</p>
<p><br><br><br><br></p>
</div>
</div>
<div class="section" id="exhaustive-grid-search-sklearn-model-selection-gridsearchcv">
<h2>Exhaustive grid search: <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"><code class="docutils literal notranslate"><span class="pre">sklearn.model_selection.GridSearchCV</span></code></a><a class="headerlink" href="#exhaustive-grid-search-sklearn-model-selection-gridsearchcv" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>For <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> we need</p>
<ul>
<li><p>an instantiated model or a pipeline</p></li>
<li><p>a parameter grid: A user specifies a set of values for each hyperparameter.</p></li>
<li><p>other optional arguments</p></li>
</ul>
</li>
</ul>
<p>The method considers product of the sets and then evaluates each combination one by one.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">pipe_svm</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">SVC</span><span class="p">(</span><span class="o">**</span><span class="n">best_parameters</span><span class="p">))</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;svc__gamma&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
    <span class="s2">&quot;svc__C&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">pipe_svm</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">set_config</span>

<span class="n">set_config</span><span class="p">(</span><span class="n">display</span><span class="o">=</span><span class="s2">&quot;diagram&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> object above behaves like a classifier. We can call <code class="docutils literal notranslate"><span class="pre">fit</span></code>, <code class="docutils literal notranslate"><span class="pre">predict</span></code> or <code class="docutils literal notranslate"><span class="pre">score</span></code> on it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1"># all the work is done here</span>
<span class="n">grid_search</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">var</span><span class="o">/</span><span class="n">folders</span><span class="o">/</span><span class="n">ky</span><span class="o">/</span><span class="mi">533</span><span class="n">nd9l512l5cmmk_kzmzj9m0000gp</span><span class="o">/</span><span class="n">T</span><span class="o">/</span><span class="n">ipykernel_97009</span><span class="o">/</span><span class="mf">3011360225.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1"># all the work is done here</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="n">grid_search</span>

<span class="nn">~/opt/miniconda3/envs/571/lib/python3.9/site-packages/sklearn/model_selection/_search.py</span> in <span class="ni">fit</span><span class="nt">(self, X, y, groups, **fit_params)</span>
<span class="g g-Whitespace">    </span><span class="mi">889</span>                 <span class="k">return</span> <span class="n">results</span>
<span class="g g-Whitespace">    </span><span class="mi">890</span> 
<span class="ne">--&gt; </span><span class="mi">891</span>             <span class="bp">self</span><span class="o">.</span><span class="n">_run_search</span><span class="p">(</span><span class="n">evaluate_candidates</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">892</span> 
<span class="g g-Whitespace">    </span><span class="mi">893</span>             <span class="c1"># multimetric is determined here because in the case of a callable</span>

<span class="nn">~/opt/miniconda3/envs/571/lib/python3.9/site-packages/sklearn/model_selection/_search.py</span> in <span class="ni">_run_search</span><span class="nt">(self, evaluate_candidates)</span>
<span class="g g-Whitespace">   </span><span class="mi">1390</span>     <span class="k">def</span> <span class="nf">_run_search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">evaluate_candidates</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">1391</span>         <span class="sd">&quot;&quot;&quot;Search all candidates in param_grid&quot;&quot;&quot;</span>
<span class="ne">-&gt; </span><span class="mi">1392</span>         <span class="n">evaluate_candidates</span><span class="p">(</span><span class="n">ParameterGrid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="p">))</span>
<span class="g g-Whitespace">   </span><span class="mi">1393</span> 
<span class="g g-Whitespace">   </span><span class="mi">1394</span> 

<span class="nn">~/opt/miniconda3/envs/571/lib/python3.9/site-packages/sklearn/model_selection/_search.py</span> in <span class="ni">evaluate_candidates</span><span class="nt">(candidate_params, cv, more_results)</span>
<span class="g g-Whitespace">    </span><span class="mi">836</span>                     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">837</span> 
<span class="ne">--&gt; </span><span class="mi">838</span>                 <span class="n">out</span> <span class="o">=</span> <span class="n">parallel</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">839</span>                     <span class="n">delayed</span><span class="p">(</span><span class="n">_fit_and_score</span><span class="p">)(</span>
<span class="g g-Whitespace">    </span><span class="mi">840</span>                         <span class="n">clone</span><span class="p">(</span><span class="n">base_estimator</span><span class="p">),</span>

<span class="nn">~/opt/miniconda3/envs/571/lib/python3.9/site-packages/joblib/parallel.py</span> in <span class="ni">__call__</span><span class="nt">(self, iterable)</span>
<span class="g g-Whitespace">   </span><span class="mi">1054</span> 
<span class="g g-Whitespace">   </span><span class="mi">1055</span>             <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backend</span><span class="o">.</span><span class="n">retrieval_context</span><span class="p">():</span>
<span class="ne">-&gt; </span><span class="mi">1056</span>                 <span class="bp">self</span><span class="o">.</span><span class="n">retrieve</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">1057</span>             <span class="c1"># Make sure that we get a last message telling us we are done</span>
<span class="g g-Whitespace">   </span><span class="mi">1058</span>             <span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_start_time</span>

<span class="nn">~/opt/miniconda3/envs/571/lib/python3.9/site-packages/joblib/parallel.py</span> in <span class="ni">retrieve</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">933</span>             <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">934</span>                 <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backend</span><span class="p">,</span> <span class="s1">&#39;supports_timeout&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">935</span>                     <span class="bp">self</span><span class="o">.</span><span class="n">_output</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">job</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">timeout</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">936</span>                 <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">937</span>                     <span class="bp">self</span><span class="o">.</span><span class="n">_output</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">job</span><span class="o">.</span><span class="n">get</span><span class="p">())</span>

<span class="nn">~/opt/miniconda3/envs/571/lib/python3.9/site-packages/joblib/_parallel_backends.py</span> in <span class="ni">wrap_future_result</span><span class="nt">(future, timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">540</span>         <span class="n">AsyncResults</span><span class="o">.</span><span class="n">get</span> <span class="kn">from</span> <span class="nn">multiprocessing.</span><span class="s2">&quot;&quot;&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">541</span><span class="s2">         try:</span>
<span class="ne">--&gt; </span><span class="mi">542</span><span class="s2">             return future.result(timeout=timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">543</span><span class="s2">         except CfTimeoutError as e:</span>
<span class="g g-Whitespace">    </span><span class="mi">544</span><span class="s2">             raise TimeoutError from e</span>

<span class="nn">~/opt/miniconda3/envs/571/lib/python3.9/concurrent/futures/_base.py</span> in <span class="ni">result</span><span class="nt">(self, timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">438</span><span class="s2">                     return self.__get_result()</span>
<span class="g g-Whitespace">    </span><span class="mi">439</span><span class="s2"> </span>
<span class="ne">--&gt; </span><span class="mi">440</span><span class="s2">                 self._condition.wait(timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">441</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">442</span><span class="s2">                 if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:</span>

<span class="nn">~/opt/miniconda3/envs/571/lib/python3.9/threading.py</span> in <span class="ni">wait</span><span class="nt">(self, timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">310</span><span class="s2">         try:    # restore state no matter what (e.g., KeyboardInterrupt)</span>
<span class="g g-Whitespace">    </span><span class="mi">311</span><span class="s2">             if timeout is None:</span>
<span class="ne">--&gt; </span><span class="mi">312</span><span class="s2">                 waiter.acquire()</span>
<span class="g g-Whitespace">    </span><span class="mi">313</span><span class="s2">                 gotit = True</span>
<span class="g g-Whitespace">    </span><span class="mi">314</span><span class="s2">             else:</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<p>Fitting the <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> object</p>
<ul class="simple">
<li><p>Searches for the best hyperparameter values</p></li>
<li><p>You can access the best score and the best hyperparameters using <code class="docutils literal notranslate"><span class="pre">best_score_</span></code> and <code class="docutils literal notranslate"><span class="pre">best_params_</span></code> attributes, respectively.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>It is often helpful to visualize results of all cross-validation experiments.</p></li>
<li><p>You can access this information using <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> attribute of a fitted <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> object.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)</span>
<span class="n">results</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;rank_test_score&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s only look at the most relevant rows.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)[</span>
    <span class="p">[</span>
        <span class="s2">&quot;mean_test_score&quot;</span><span class="p">,</span>
        <span class="s2">&quot;param_svc__gamma&quot;</span><span class="p">,</span>
        <span class="s2">&quot;param_svc__C&quot;</span><span class="p">,</span>
        <span class="s2">&quot;mean_fit_time&quot;</span><span class="p">,</span>
        <span class="s2">&quot;rank_test_score&quot;</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">]</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;rank_test_score&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Other than searching for best hyperparameter values, <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> also fits a new model on the whole training set with the parameters that yielded the best results.</p></li>
<li><p>So we can conveniently call <code class="docutils literal notranslate"><span class="pre">score</span></code> on the test set with a fitted <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> object.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Why <code class="docutils literal notranslate"><span class="pre">best_score_</span></code> and the score above are different?</p>
<div class="section" id="n-jobs-1">
<h3><code class="docutils literal notranslate"><span class="pre">n_jobs=-1</span></code><a class="headerlink" href="#n-jobs-1" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Note the <code class="docutils literal notranslate"><span class="pre">n_jobs=-1</span></code> above.</p></li>
<li><p>Hyperparameter optimization can be done <em>in parallel</em> for each of the configurations.</p></li>
<li><p>This is very useful when scaling up to large numbers of machines in the cloud.</p></li>
</ul>
</div>
<div class="section" id="the-syntax">
<h3>The <code class="docutils literal notranslate"><span class="pre">__</span></code> syntax<a class="headerlink" href="#the-syntax" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Above: we have a nesting of transformers.</p></li>
<li><p>We can access the parameters of the “inner” objects by using __ to go “deeper”:</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">svc__gamma</span></code>: the <code class="docutils literal notranslate"><span class="pre">gamma</span></code> of the <code class="docutils literal notranslate"><span class="pre">svc</span></code> of the pipeline</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">svc__C</span></code>: the <code class="docutils literal notranslate"><span class="pre">C</span></code> of the <code class="docutils literal notranslate"><span class="pre">svc</span></code> of the pipeline</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">pipe_svm</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">SVC</span><span class="p">(</span><span class="o">**</span><span class="n">best_parameters</span><span class="p">))</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;svc__gamma&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
    <span class="s2">&quot;svc__C&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">pipe_svm</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="visualizing-the-parameter-grid-as-a-heatmap">
<h3>Visualizing the parameter grid as a heatmap<a class="headerlink" href="#visualizing-the-parameter-grid-as-a-heatmap" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">mean_test_score</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>

<span class="c1"># plot the mean cross-validation scores</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span>
    <span class="n">scores</span><span class="p">,</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;gamma&quot;</span><span class="p">,</span>
    <span class="n">xticklabels</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;svc__gamma&quot;</span><span class="p">],</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">,</span>
    <span class="n">yticklabels</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;svc__C&quot;</span><span class="p">],</span>
    <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;viridis&quot;</span><span class="p">,</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Each point in the heat map corresponds to one run of cross-validation, with a particular setting</p></li>
<li><p>Colour encodes cross-validation accuracy.</p>
<ul>
<li><p>Lighter colour means high accuracy</p></li>
<li><p>Darker colour means low accuracy</p></li>
</ul>
</li>
<li><p>SVC is quite sensitive to hyperparameter settings.</p></li>
<li><p>Adjusting hyperparameters can change the accuracy from 0.51 to 0.74!</p></li>
</ul>
<ul class="simple">
<li><p>Note that the range we pick for the parameters play an important role in hyperparameter optimization.</p></li>
<li><p>For example, consider the following grid and the corresponding results.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">display_heatmap</span><span class="p">(</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">):</span>
    <span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
        <span class="n">pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">mean_test_score</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>

    <span class="c1"># plot the mean cross-validation scores</span>
    <span class="n">mglearn</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span>
        <span class="n">scores</span><span class="p">,</span>
        <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;gamma&quot;</span><span class="p">,</span>
        <span class="n">xticklabels</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;svc__gamma&quot;</span><span class="p">],</span>
        <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">,</span>
        <span class="n">yticklabels</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;svc__C&quot;</span><span class="p">],</span>
        <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;viridis&quot;</span><span class="p">,</span>
    <span class="p">);</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="bad-range-for-hyperparameters">
<h3>Bad range for hyperparameters<a class="headerlink" href="#bad-range-for-hyperparameters" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid2</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;svc__gamma&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="s2">&quot;svc__C&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">)}</span>
<span class="n">display_heatmap</span><span class="p">(</span><span class="n">param_grid2</span><span class="p">,</span> <span class="n">pipe_svm</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="different-range-for-hyperparameters-yields-better-results">
<h3>Different range for hyperparameters yields better results!<a class="headerlink" href="#different-range-for-hyperparameters-yields-better-results" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid3</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;svc__gamma&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="s2">&quot;svc__C&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">)}</span>

<span class="n">display_heatmap</span><span class="p">(</span><span class="n">param_grid3</span><span class="p">,</span> <span class="n">pipe_svm</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>It seems like we are getting even better cross-validation results with <code class="docutils literal notranslate"><span class="pre">C</span></code> = 2.0 and <code class="docutils literal notranslate"><span class="pre">gamma</span></code> = 0.1</p>
<p>How about exploring different values of <code class="docutils literal notranslate"><span class="pre">C</span></code> close to 2.0?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid4</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;svc__gamma&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="s2">&quot;svc__C&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">)}</span>

<span class="n">display_heatmap</span><span class="p">(</span><span class="n">param_grid4</span><span class="p">,</span> <span class="n">pipe_svm</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>That’s good! We are finding some more options for <code class="docutils literal notranslate"><span class="pre">C</span></code> where the accuracy is 0.75.
The tricky part is we do not know in advance what range of hyperparameters might work the best for the given problem, model, and the dataset.</p>
</div>
<div class="section" id="true-false">
<h3>True/False<a class="headerlink" href="#true-false" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>If you get optimal results at the edges of your parameter grid, it might be a good idea to adjust the range of values in your parameter grid.</p></li>
<li><p>Grid search is guaranteed to find best hyperparameters values.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> allows the param_grid to be a list of dictionaries. Sometimes some hyperparameters are applicable only for certain models.
For example, in the context of <code class="docutils literal notranslate"><span class="pre">SVC</span></code>, <code class="docutils literal notranslate"><span class="pre">C</span></code> and <code class="docutils literal notranslate"><span class="pre">gamma</span></code> are applicable when the kernel is <code class="docutils literal notranslate"><span class="pre">rbf</span></code> whereas only <code class="docutils literal notranslate"><span class="pre">C</span></code> is applicable for <code class="docutils literal notranslate"><span class="pre">kernel=&quot;linear&quot;</span></code>.</p>
</div>
</div>
<div class="section" id="problems-with-exhaustive-grid-search">
<h3>Problems with exhaustive grid search<a class="headerlink" href="#problems-with-exhaustive-grid-search" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Required number of models to evaluate grows exponentially with the dimensionally of the configuration space.</p></li>
<li><p>Example: Suppose you have</p>
<ul>
<li><p>5 hyperparameters</p></li>
<li><p>10 different values for each hyperparameter</p></li>
<li><p>You’ll be evaluating <span class="math notranslate nohighlight">\(10^5=100,000\)</span> models! That is you’ll be calling <code class="docutils literal notranslate"><span class="pre">cross_validate</span></code> 100,000 times!</p></li>
</ul>
</li>
<li><p>Exhaustive search may become infeasible fairly quickly.</p></li>
<li><p>Other options?</p></li>
</ul>
<p><br><br><br><br></p>
</div>
</div>
<div class="section" id="randomized-hyperparameter-search">
<h2>Randomized hyperparameter search<a class="headerlink" href="#randomized-hyperparameter-search" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Randomized hyperparameter optimization</p>
<ul>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html"><code class="docutils literal notranslate"><span class="pre">sklearn.model_selection.RandomizedSearchCV</span></code></a></p></li>
</ul>
</li>
<li><p>Samples configurations at random until certain budget (e.g., time) is exhausted</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RandomizedSearchCV</span>


<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;svc__gamma&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
    <span class="s2">&quot;svc__C&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
<span class="p">}</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Grid size: </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">len</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">.</span><span class="n">values</span><span class="p">())))))</span>
<span class="n">param_grid</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
    <span class="n">pipe_svm</span><span class="p">,</span> <span class="n">param_distributions</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span>
<span class="p">)</span>
<span class="n">random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">random_search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)[</span>
    <span class="p">[</span>
        <span class="s2">&quot;mean_test_score&quot;</span><span class="p">,</span>
        <span class="s2">&quot;param_svc__gamma&quot;</span><span class="p">,</span>
        <span class="s2">&quot;param_svc__C&quot;</span><span class="p">,</span>
        <span class="s2">&quot;mean_fit_time&quot;</span><span class="p">,</span>
        <span class="s2">&quot;rank_test_score&quot;</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">]</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;rank_test_score&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="n-iter">
<h3><code class="docutils literal notranslate"><span class="pre">n_iter</span></code><a class="headerlink" href="#n-iter" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Note the <code class="docutils literal notranslate"><span class="pre">n_iter</span></code>, we didn’t need this for <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code>.</p></li>
<li><p>Larger <code class="docutils literal notranslate"><span class="pre">n_iter</span></code> will take longer but it’ll do more searching.</p>
<ul>
<li><p>Remember you still need to multiply by number of folds!</p></li>
</ul>
</li>
<li><p>I have also set <code class="docutils literal notranslate"><span class="pre">random_state</span></code> but you don’t have to do it.</p></li>
</ul>
</div>
<div class="section" id="range-of-c">
<h3>Range of <code class="docutils literal notranslate"><span class="pre">C</span></code><a class="headerlink" href="#range-of-c" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Note the exponential range for <code class="docutils literal notranslate"><span class="pre">C</span></code>. This is quite common.</p></li>
<li><p>There is no point trying <span class="math notranslate nohighlight">\(C=\{1,2,3\ldots,100\}\)</span> because <span class="math notranslate nohighlight">\(C=1,2,3\)</span> are too similar to each other.</p></li>
<li><p>Often we’re trying to find an order of magnitude, e.g. <span class="math notranslate nohighlight">\(C=\{0.01,0.1,1,10,100\}\)</span>.</p></li>
<li><p>We can also write that as <span class="math notranslate nohighlight">\(C=\{10^{-2},10^{-1},10^0,10^1,10^2\}\)</span>.</p></li>
<li><p>Or, in other words, <span class="math notranslate nohighlight">\(C\)</span> values to try are <span class="math notranslate nohighlight">\(10^n\)</span> for <span class="math notranslate nohighlight">\(n=-2,-1,0,1,2\)</span> which is basically what we have above.</p></li>
</ul>
<p>(Optional) Another thing we can do is give probability distributions to draw from:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">expon</span><span class="p">,</span> <span class="n">lognorm</span><span class="p">,</span> <span class="n">loguniform</span><span class="p">,</span> <span class="n">randint</span><span class="p">,</span> <span class="n">uniform</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_dist</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;svc__C&quot;</span><span class="p">:</span> <span class="n">uniform</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1e4</span><span class="p">),</span>  <span class="c1"># loguniform(1e-3, 1e3),</span>
    <span class="s2">&quot;svc__gamma&quot;</span><span class="p">:</span> <span class="n">loguniform</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e3</span><span class="p">),</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
    <span class="n">pipe_svm</span><span class="p">,</span> <span class="n">param_dist</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random_search</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">random_search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)[</span>
    <span class="p">[</span>
        <span class="s2">&quot;mean_test_score&quot;</span><span class="p">,</span>
        <span class="s2">&quot;param_svc__gamma&quot;</span><span class="p">,</span>
        <span class="s2">&quot;param_svc__C&quot;</span><span class="p">,</span>
        <span class="s2">&quot;mean_fit_time&quot;</span><span class="p">,</span>
        <span class="s2">&quot;rank_test_score&quot;</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">]</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;rank_test_score&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>This is a bit fancy. What’s nice is that you can have it concentrate more on certain values by setting the distribution.</p></li>
</ul>
</div>
<div class="section" id="advantages-of-randomizedsearchcv">
<h3>Advantages of <code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code><a class="headerlink" href="#advantages-of-randomizedsearchcv" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Faster compared to <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code>.</p></li>
<li><p>Adding parameters that do not influence the performance does not affect efficiency.</p></li>
<li><p>Works better when some parameters are more important than others.</p></li>
<li><p>In general, I recommend using <code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code> rather than <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code>.</p></li>
</ul>
</div>
<div class="section" id="id1">
<h3>Advantages of <code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code><a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p><img alt="" src="../_images/randomsearch_bergstra.png" /></p>
<p>Source: <a class="reference external" href="http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf">Bergstra and Bengio, Random Search for Hyper-Parameter Optimization, JMLR 2012</a>.</p>
<ul class="simple">
<li><p>The yellow on the left shows how your scores are going to change when you vary the unimportant hyperparameter.</p></li>
<li><p>The green on the top shows how your scores are  going to change when you vary the important hyperparameter.</p></li>
<li><p>You don’t know in advance which hyperparameters are important for your problem.</p></li>
<li><p>In the left figure, 6 of the 9 searches are useless because they are only varying the unimportant parameter.</p></li>
<li><p>In the right figure, all 9 searches are useful.</p></li>
</ul>
</div>
</div>
<div class="section" id="fancier-methods-optional">
<h2>Fancier methods (optional)<a class="headerlink" href="#fancier-methods-optional" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Both <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> and <code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code> do each trial independently.</p></li>
<li><p>What if you could learn from your experience, e.g. learn that <code class="docutils literal notranslate"><span class="pre">max_depth=3</span></code> is bad?</p>
<ul>
<li><p>That could save time because you wouldn’t try combinations involving <code class="docutils literal notranslate"><span class="pre">max_depth=3</span></code> in the future.</p></li>
</ul>
</li>
<li><p>We can do this with <code class="docutils literal notranslate"><span class="pre">scikit-optimize</span></code>, which is a completely different package from <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code></p></li>
<li><p>It uses a technique called “model-based optimization” and we’ll specifically use “Bayesian optimization”.</p>
<ul>
<li><p>In short, it uses machine learning to predict what hyperparameters will be good.</p></li>
<li><p>Machine learning on machine learning!</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>This is an active research area and there are sophisticated packages for this.</p></li>
</ul>
<p>Here are some examples</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/hyperopt/hyperopt-sklearn">hyperopt-sklearn</a></p></li>
<li><p><a class="reference external" href="https://github.com/automl/auto-sklearn">auto-sklearn</a></p></li>
<li><p><a class="reference external" href="https://sigopt.com/docs/overview/scikit_learn">SigOptSearchCV</a></p></li>
<li><p><a class="reference external" href="https://github.com/rhiever/tpot">TPOT</a></p></li>
<li><p><a class="reference external" href="https://github.com/hyperopt/hyperopt">hyperopt</a></p></li>
<li><p><a class="reference external" href="https://github.com/zygmuntz/hyperband">hyperband</a></p></li>
<li><p><a class="reference external" href="http://www.cs.ubc.ca/labs/beta/Projects/SMAC/">SMAC</a></p></li>
<li><p><a class="reference external" href="https://github.com/Yelp/MOE">MOE</a></p></li>
<li><p><a class="reference external" href="https://github.com/mwhoffman/pybo">pybo</a></p></li>
<li><p><a class="reference external" href="https://github.com/HIPS/Spearmint">spearmint</a></p></li>
<li><p><a class="reference external" href="https://github.com/rmcantin/bayesopt">BayesOpt</a></p></li>
</ul>
<div class="section" id="questions-for-class-discussion-hyperparameter-optimization">
<h3>Questions for class discussion (hyperparameter optimization)<a class="headerlink" href="#questions-for-class-discussion-hyperparameter-optimization" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Suppose you have 10 hyperparameters, each with 4 possible values. If you run <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> with this parameter grid, how many cross-validation experiments it would carry out?</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> exhaustively searches the grid and so it’s guaranteed to give you the optimal hyperparameters for the given problem.</p></li>
<li><p>It is possible to get different hyperparameters in different runs of <code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code>.</p></li>
<li><p>Suppose you have 10 hyperparameters and each takes 4 values. If you run <code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code> with this parameter grid, how many cross-validation experiments it would carry out?</p></li>
</ul>
<p><br><br><br><br></p>
</div>
</div>
<div class="section" id="optimization-bias-overfitting-of-the-validation-set">
<h2>Optimization bias/Overfitting of the validation set<a class="headerlink" href="#optimization-bias-overfitting-of-the-validation-set" title="Permalink to this headline">¶</a></h2>
<div class="section" id="overfitting-of-the-validation-error">
<h3>Overfitting of the validation error<a class="headerlink" href="#overfitting-of-the-validation-error" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Why do we need to evaluate the model on the test set in the end?</p></li>
<li><p>Why not just use cross-validation on the whole dataset?</p></li>
<li><p>While carrying out hyperparameter optimization, we usually try over many possibilities.</p></li>
<li><p>If our dataset is small and if your validation set is hit too many times, we suffer from <strong>optimization bias</strong> or <strong>overfitting the validation set</strong>.</p></li>
</ul>
</div>
<div class="section" id="optimization-bias-of-parameter-learning">
<h3>Optimization bias of parameter learning<a class="headerlink" href="#optimization-bias-of-parameter-learning" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Overfitting of the training error</p></li>
<li><p>An example:</p>
<ul>
<li><p>During training, we could search over tons of different decision trees.</p></li>
<li><p>So we can get “lucky” and find one with low training error by chance.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="optimization-bias-of-hyper-parameter-learning">
<h3>Optimization bias of hyper-parameter learning<a class="headerlink" href="#optimization-bias-of-hyper-parameter-learning" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Overfitting of the validation error</p></li>
<li><p>An example:</p>
<ul>
<li><p>Here, we might optimize the validation error over 1000 values of <code class="docutils literal notranslate"><span class="pre">max_depth</span></code>.</p></li>
<li><p>One of the 1000 trees might have low validation error by chance.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="example-1-optimization-bias-optional">
<h3>Example 1: Optimization bias (optional)<a class="headerlink" href="#example-1-optimization-bias-optional" title="Permalink to this headline">¶</a></h3>
<p>Consider a multiple-choice (a,b,c,d) “test” with 10 questions:</p>
<ul class="simple">
<li><p>If you choose answers randomly, expected grade is 25% (no bias).</p></li>
<li><p>If you fill out two tests randomly and pick the best, expected grade is 33%.</p>
<ul>
<li><p>Optimization bias of ~8%.</p></li>
</ul>
</li>
<li><p>If you take the best among 10 random tests, expected grade is ~47%.</p></li>
<li><p>If you take the best among 100, expected grade is ~62%.</p></li>
<li><p>If you take the best among 1000, expected grade is ~73%.</p></li>
<li><p>If you take the best among 10000, expected grade is ~82%.</p>
<ul>
<li><p>You have so many “chances” that you expect to do well.</p></li>
</ul>
</li>
</ul>
<p><strong>But on new questions the “random choice” accuracy is still 25%.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># (optional) Code attribution: Rodolfo Lourenzutti</span>
<span class="n">number_tests</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">]</span>
<span class="k">for</span> <span class="n">ntests</span> <span class="ow">in</span> <span class="n">number_tests</span><span class="p">:</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">):</span>
        <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="n">ntests</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="s2">&quot;The expected grade among the best of </span><span class="si">%d</span><span class="s2"> tests is : </span><span class="si">%0.2f</span><span class="s2">&quot;</span>
        <span class="o">%</span> <span class="p">(</span><span class="n">ntests</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="mf">10.0</span><span class="p">)</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="example-2-optimization-bias-optional">
<h3>Example 2: Optimization bias (optional)<a class="headerlink" href="#example-2-optimization-bias-optional" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>If we instead used a 100-question test then:</p>
<ul>
<li><p>Expected grade from best over 1 randomly-filled test is 25%.</p></li>
<li><p>Expected grade from best over 2 randomly-filled test is ~27%.</p></li>
<li><p>Expected grade from best over 10 randomly-filled test is ~32%.</p></li>
<li><p>Expected grade from best over 100 randomly-filled test is ~36%.</p></li>
<li><p>Expected grade from best over 1000 randomly-filled test is ~40%.</p></li>
<li><p>Expected grade from best over 10000 randomly-filled test is ~43%.</p></li>
</ul>
</li>
<li><p>The optimization bias <strong>grows with the number of things we try</strong>.</p>
<ul>
<li><p>“Complexity” of the set of models we search over.</p></li>
</ul>
</li>
<li><p>But, optimization bias <strong>shrinks quickly with the number of examples</strong>.</p>
<ul>
<li><p>But it’s still non-zero and growing if you over-use your validation set!</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># (optional) Code attribution: Rodolfo Lourenzutti</span>
<span class="n">number_tests</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">]</span>
<span class="k">for</span> <span class="n">ntests</span> <span class="ow">in</span> <span class="n">number_tests</span><span class="p">:</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">):</span>
        <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="mf">100.0</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="n">ntests</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="s2">&quot;The expected grade among the best of </span><span class="si">%d</span><span class="s2"> tests is : </span><span class="si">%0.2f</span><span class="s2">&quot;</span>
        <span class="o">%</span> <span class="p">(</span><span class="n">ntests</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="mf">100.0</span><span class="p">)</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="optimization-bias-on-the-spotify-dataset">
<h3>Optimization bias on the Spotify dataset<a class="headerlink" href="#optimization-bias-on-the-spotify-dataset" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_tiny</span><span class="p">,</span> <span class="n">X_test_big</span><span class="p">,</span> <span class="n">y_train_tiny</span><span class="p">,</span> <span class="n">y_test_big</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_spotify</span><span class="p">,</span> <span class="n">y_spotify</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_tiny</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_tiny</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">SVC</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RandomizedSearchCV</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;svc__gamma&quot;</span><span class="p">:</span> <span class="mf">10.0</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="s2">&quot;svc__C&quot;</span><span class="p">:</span> <span class="mf">10.0</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
<span class="p">}</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Grid size: </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">len</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">.</span><span class="n">values</span><span class="p">())))))</span>
<span class="n">param_grid</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
    <span class="n">pipe</span><span class="p">,</span> <span class="n">param_distributions</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span>
<span class="p">)</span>
<span class="n">random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_tiny</span><span class="p">,</span> <span class="n">y_train_tiny</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">random_search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)[</span>
    <span class="p">[</span>
        <span class="s2">&quot;mean_test_score&quot;</span><span class="p">,</span>
        <span class="s2">&quot;param_svc__gamma&quot;</span><span class="p">,</span>
        <span class="s2">&quot;param_svc__C&quot;</span><span class="p">,</span>
        <span class="s2">&quot;mean_fit_time&quot;</span><span class="p">,</span>
        <span class="s2">&quot;rank_test_score&quot;</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">]</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;rank_test_score&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
</div>
<p>Given the results: one might claim that we found a model that performs with 0.8 accuracy on our dataset.</p>
<ul class="simple">
<li><p>Do we really believe that 0.80 is a good estimate of our test data?</p></li>
<li><p>Do we really believe that <code class="docutils literal notranslate"><span class="pre">gamma</span></code>=0.0 and C=1_000_000_000 are the best hyperparameters?</p></li>
</ul>
<ul class="simple">
<li><p>Let’s find out the test score with this best model.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random_search</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>The results above are overly optimistic.</p>
<ul>
<li><p>because our training data is very small and so our validation splits in cross validation would be small.</p></li>
<li><p>because of the small dataset and the fact that we hit the small validation set 900 times and it’s possible that we got lucky on the validation set!</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>As we suspected, the best cross-validation score is not a good estimate of our test data; it is overly optimistic.</p></li>
<li><p>We can trust this test score because the test set is of good size.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_test_big</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="overfitting-of-the-validation-data">
<h3>Overfitting of the validation data<a class="headerlink" href="#overfitting-of-the-validation-data" title="Permalink to this headline">¶</a></h3>
<p>The following plot demonstrates what happens during overfitting of the validation data.</p>
<center>
<img src='./img/optimization-bias.png' width="600">
</center>
<p><a class="reference external" href="https://amueller.github.io/COMS4995-s20/slides/aml-03-supervised-learning/#20">Source</a></p>
<ul class="simple">
<li><p>Thus, not only can we not trust the cv scores, we also cannot trust cv’s ability to choose of the best hyperparameters.</p></li>
</ul>
</div>
<div class="section" id="why-do-we-need-a-test-set">
<h3>Why do we need a test set?<a class="headerlink" href="#why-do-we-need-a-test-set" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>This is why we need a test set.</p></li>
<li><p>The frustrating part is that if our dataset is small then our test set is also small 😔.</p></li>
<li><p>But we don’t have a lot of better alternatives, unfortunately, if we have a small dataset.</p></li>
</ul>
</div>
<div class="section" id="when-test-score-is-much-lower-than-cv-score">
<h3>When test score is much lower than CV score<a class="headerlink" href="#when-test-score-is-much-lower-than-cv-score" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>What to do if your test score is much lower than your cross-validation score:</p>
<ul>
<li><p>Try simpler models and use the test set a couple of times; it’s not the end of the world.</p></li>
<li><p>Communicate this clearly when you report the results.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="large-datasets-solve-many-of-these-problems">
<h3>Large datasets solve many of these problems<a class="headerlink" href="#large-datasets-solve-many-of-these-problems" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>With infinite amounts of training data, overfitting would not be a problem and you could have your test score = your train score.</p>
<ul>
<li><p>Overfitting happens because you only see a bit of data and you learn patterns that are overly specific to your sample.</p></li>
<li><p>If you saw “all” the data, then the notion of “overly specific” would not apply.</p></li>
</ul>
</li>
<li><p>So, more data will make your test score better and robust.</p></li>
</ul>
</div>
<div class="section" id="questions-for-you">
<h3>❓❓ Questions for you<a class="headerlink" href="#questions-for-you" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="would-you-trust-the-model">
<h3>Would you trust the model?<a class="headerlink" href="#would-you-trust-the-model" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>You have a dataset and you give me half of it. I build a model using all the data you have given me and I tell you that the model accuracy is 0.99. Would it classify the rest of the data with similar accuracy?</p></li>
</ul>
<ol class="simple">
<li><p>Probably</p></li>
<li><p>Probably not</p></li>
</ol>
</div>
<div class="section" id="id2">
<h3>Would you trust the model?<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>You have a dataset and you give me half of it. I build a model using 80% of the data given to me and report the accuracy of 0.95 on the remaining 20% of the data. Would it classify the rest of the data with similar accuracy?</p></li>
</ul>
<ol class="simple">
<li><p>Probably</p></li>
<li><p>Probably not</p></li>
</ol>
</div>
<div class="section" id="id3">
<h3>Would you trust the model?<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>You have a dataset and you give me 1/10th of it. The dataset given to me is rather small and so I split it into 96% train and 4% validation split. I carry out hyperparameter optimization using a single 4% validation split and report validation accuracy of 0.97. Would it classify the rest of the data with similar accuracy?</p></li>
</ul>
<ol class="simple">
<li><p>Probably</p></li>
<li><p>Probably not</p></li>
</ol>
</div>
</div>
<div class="section" id="final-comments-and-summary">
<h2>Final comments and summary<a class="headerlink" href="#final-comments-and-summary" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id4">
<h3>Automated hyperparameter optimization<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Advantages</p>
<ul>
<li><p>reduce human effort</p></li>
<li><p>less prone to error and improve reproducibility</p></li>
<li><p>data-driven approaches may be effective</p></li>
</ul>
</li>
<li><p>Disadvantages</p>
<ul>
<li><p>may be hard to incorporate intuition</p></li>
<li><p>be careful about overfitting on the validation set</p></li>
</ul>
</li>
</ul>
<p>Often, especially on typical datasets, we get back <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>’s default hyperparameter values. This means that the defaults are well chosen by <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> developers!</p>
<ul class="simple">
<li><p>The problem of finding the best values for the important hyperparameters is tricky because</p>
<ul>
<li><p>You may have a lot of them (e.g. deep learning).</p></li>
<li><p>You may have multiple hyperparameters which may interact with each other in unexpected ways.</p></li>
</ul>
</li>
<li><p>The best settings depend on the specific data/problem.</p></li>
</ul>
</div>
</div>
<div class="section" id="optional-readings-and-resources">
<h2>Optional readings and resources<a class="headerlink" href="#optional-readings-and-resources" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="http://www.robotics.stanford.edu/~ang/papers/cv-final.pdf">Preventing “overfitting” of cross-validation data</a> by Andrew Ng</p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "conda-env-571-py"
        },
        kernelOptions: {
            kernelName: "conda-env-571-py",
            path: "./lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'conda-env-571-py'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="07_linear-models.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Lecture 7: Linear Models</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="09_classification-metrics.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Lecture 9: Classification Metrics</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Varada Kolhatkar<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>