{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](img/330-banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Lecture 7: Hyperparameter optimization and optimization bias\n",
    "\n",
    "UBC 2020-21\n",
    "\n",
    "Instructor: Varada Kolhatkar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Preprocessing and pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# train test split and cross validation\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lecture plan for today\n",
    "\n",
    "- TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Announcements\n",
    "\n",
    "- TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Learning outcomes \n",
    "\n",
    "From this lecture, you will be able to \n",
    "\n",
    "- explain the need for hyperparameter optimization  \n",
    "- carry out hyperparameter optimization using `sklearn`'s `GridSearchCV` and `RandomizedSearchCV` \n",
    "- explain optimization bias\n",
    "- identify and reason when to trust and not trust reported accuracies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Lecture outline\n",
    "\n",
    "1. [Introduction and motivation](#1)\n",
    "2. [Hyperparameter optimization](#2)\n",
    "3. [Optimization bias](#3)\n",
    "4. [Summary](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hyperparameter optimization introduction and motivation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation\n",
    "\n",
    "- Remember that the fundamental goal of supervised machine is to generalize beyond what we see in the training examples. \n",
    "- We have been using data splitting and cross-validation to provide a framework to approximate generalization error.  \n",
    "- With this framework, we can improve the model's generalization performance by tuning model hyperparameters using cross-validation on the training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In homework assignments, we have been carrying out hyperparameter search by exhaustively trying all possible combinations of the hyperparameters of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 700x210 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mglearn.plots.plot_grid_search_overview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example of training SVM RBF classifier on the Spotify dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features in the Spotify dataset: 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.833</td>\n",
       "      <td>204600</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>-8.795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>150.062</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1990</td>\n",
       "      <td>0.743</td>\n",
       "      <td>326933</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>-10.401</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>160.083</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.838</td>\n",
       "      <td>185707</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>-7.148</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2890</td>\n",
       "      <td>75.044</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6040</td>\n",
       "      <td>0.494</td>\n",
       "      <td>199413</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>-15.236</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>86.468</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.678</td>\n",
       "      <td>392893</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>-11.648</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>174.004</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_ms  energy  instrumentalness  key  \\\n",
       "0        0.0102         0.833       204600   0.434          0.021900    2   \n",
       "1        0.1990         0.743       326933   0.359          0.006110    1   \n",
       "2        0.0344         0.838       185707   0.412          0.000234    2   \n",
       "3        0.6040         0.494       199413   0.338          0.510000    5   \n",
       "4        0.1800         0.678       392893   0.561          0.512000    5   \n",
       "\n",
       "   liveness  loudness  mode  speechiness    tempo  time_signature  valence  \n",
       "0    0.1650    -8.795     1       0.4310  150.062             4.0    0.286  \n",
       "1    0.1370   -10.401     1       0.0794  160.083             4.0    0.588  \n",
       "2    0.1590    -7.148     1       0.2890   75.044             4.0    0.173  \n",
       "3    0.0922   -15.236     1       0.0261   86.468             4.0    0.230  \n",
       "4    0.4390   -11.648     0       0.0694  174.004             4.0    0.904  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_df = pd.read_csv(\"data/spotify.csv\", index_col=0)\n",
    "X_spotify = spotify_df.drop(columns=[\"target\", \"song_title\", \"artist\"])\n",
    "print(\"The number of features in the Spotify dataset: %d\" % X_spotify.shape[1])\n",
    "X_spotify.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_spotify = spotify_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_spotify, y_spotify, test_size=0.2, random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()), ('svc', SVC())])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_svm = make_pipeline(StandardScaler(), SVC())\n",
    "pipe_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try cross-validation with default hyperparameters of SVC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.047906\n",
       "score_time     0.024358\n",
       "test_score     0.738998\n",
       "train_score    0.814011\n",
       "dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(pipe_svm, X_train, y_train, return_train_score=True)\n",
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try exhaustive hyperparameter search using for loops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    \"gamma\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "}\n",
    "\n",
    "results_dict = {\"C\": [], \"gamma\": [], \"mean_cv_score\": []}\n",
    "\n",
    "for gamma in param_grid[\"gamma\"]:\n",
    "    for C in param_grid[\"C\"]:  # for each combination of parameters, train an SVC\n",
    "        pipe_svm = make_pipeline(StandardScaler(), SVC(gamma=gamma, C=C))\n",
    "        scores = cross_val_score(pipe_svm, X_train, y_train)  # perform cross-validation\n",
    "        mean_score = np.mean(scores)  # compute mean cross-validation accuracy\n",
    "        if (\n",
    "            mean_score > best_score\n",
    "        ):  # if we got a better score, store the score and parameters\n",
    "            best_score = mean_score\n",
    "            best_parameters = {\"C\": C, \"gamma\": gamma}\n",
    "        results_dict[\"C\"].append(C)\n",
    "        results_dict[\"gamma\"].append(gamma)\n",
    "        results_dict[\"mean_cv_score\"].append(mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 0.1}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7439609253312309"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(search_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>mean_cv_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.743961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.732792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.729091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.720391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.711715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.704284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.703034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.697473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.678851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.678244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.671425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.671425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.668335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.652824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>100.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.515190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.515190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.511469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.508371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>10.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.508371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.508371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.010</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.507750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.001</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.507750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.010</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.507750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.100</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.507750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.100</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.507750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.507750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.001</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.507750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.507750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.507750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.507750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.507750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.507750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.507750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.507750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.507750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.507750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          C    gamma  mean_cv_score\n",
       "15    1.000    0.100       0.743961\n",
       "11  100.000    0.010       0.732792\n",
       "16   10.000    0.100       0.729091\n",
       "10   10.000    0.010       0.720391\n",
       "17  100.000    0.100       0.711715\n",
       "5   100.000    0.001       0.704284\n",
       "14    0.100    0.100       0.703034\n",
       "9     1.000    0.010       0.697473\n",
       "8     0.100    0.010       0.678851\n",
       "4    10.000    0.001       0.678244\n",
       "23  100.000    1.000       0.671425\n",
       "22   10.000    1.000       0.671425\n",
       "21    1.000    1.000       0.668335\n",
       "3     1.000    0.001       0.652824\n",
       "29  100.000   10.000       0.515190\n",
       "28   10.000   10.000       0.515190\n",
       "27    1.000   10.000       0.511469\n",
       "33    1.000  100.000       0.508371\n",
       "34   10.000  100.000       0.508371\n",
       "35  100.000  100.000       0.508371\n",
       "31    0.010  100.000       0.507750\n",
       "30    0.001  100.000       0.507750\n",
       "25    0.010   10.000       0.507750\n",
       "32    0.100  100.000       0.507750\n",
       "26    0.100   10.000       0.507750\n",
       "0     0.001    0.001       0.507750\n",
       "24    0.001   10.000       0.507750\n",
       "20    0.100    1.000       0.507750\n",
       "19    0.010    1.000       0.507750\n",
       "1     0.010    0.001       0.507750\n",
       "13    0.010    0.100       0.507750\n",
       "12    0.001    0.100       0.507750\n",
       "7     0.010    0.010       0.507750\n",
       "6     0.001    0.010       0.507750\n",
       "2     0.100    0.001       0.507750\n",
       "18    0.001    1.000       0.507750"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=\"mean_cv_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = np.array(df.mean_cv_score).reshape(6, 6)\n",
    "\n",
    "mglearn.tools.heatmap(\n",
    "    scores,\n",
    "    xlabel=\"gamma\",\n",
    "    xticklabels=param_grid[\"gamma\"],\n",
    "    ylabel=\"C\",\n",
    "    yticklabels=param_grid[\"C\"],\n",
    "    cmap=\"viridis\",\n",
    ")\n",
    "# plot the mean cross-validation scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have 6 possible values for `C` and 6 possible values for `gamma`. \n",
    "- In 5-fold cross-validation, for each combination of parameter values, five accuracies are computed.\n",
    "- So to evaluate the accuracy of the SVM using 6 values of C and 6 values of gamma using five-fold cross-validation, we need to train 36 * 5 = 180 models! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have optimized hyperparameters, we retrain a model on the full training set with these optimized hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(C=1, gamma=0.1))])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_svm = make_pipeline(StandardScaler(), SVC(**best_parameters))\n",
    "pipe_svm.fit(\n",
    "    X_train, y_train\n",
    ")  # Retrain a model with optimized hyperparameters on the combined training and validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally evaluate the performance of this model on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7376237623762376"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_svm.score(X_test, y_test)  # Final evaluation on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very common process in supervised machine learning pipelines and there are some standard method in `scikit-learn` to help with this.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hyperparameters: the problem\n",
    "\n",
    "- In order to get the best generalization performance, finding the best values for the important hyperparameters of a model is necessary for almost all models and datasets. \n",
    "- Picking reasonable hyperparameters is important because if we don't do it, we might end up with an underfit or overfit model. \n",
    "- The problem of finding the best values for the important hyperparameters is tricky because \n",
    "    - You may have a lot of them (e.g. deep learning). \n",
    "    - You may have multiple hyperparameters which may interact with each other in unexpected ways.    \n",
    "- The best settings depend on the specific data/problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some ways to pick hyperparameters:\n",
    "- Manual or expert knowledge or heuristics based optimization \n",
    "- Data-driven or automated optimization (this lecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Manual hyperparameter optimization\n",
    "\n",
    "- Advantage: we may have some intuition about what might work.\n",
    "  - E.g. if I'm massively overfitting, try decreasing `max_depth` or `C`.\n",
    "- Disadvantage: it takes a lot of work.\n",
    "- Disadvantage: in very complicated cases, our intuition might be worse than a data-driven approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automated hyperparameter optimization\n",
    "\n",
    "- Advantages \n",
    "    - reduce human effort\n",
    "    - less prone to error and improve reproducibility\n",
    "    - data-driven approaches may be effective\n",
    "- Disadvantages\n",
    "    - may be hard to incorporate intuition\n",
    "    - be careful about overfitting on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hyperparameter optimization with `scikit-learn`\n",
    "There are two automated hyperparameter search methods in `scikit-learn`:\n",
    "\n",
    "- Exhaustive grid search: [`sklearn.model_selection.GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "- Randomized hyperparameter optimization: [`sklearn.model_selection.RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "  \n",
    "The \"CV\" stands for cross-validation; these methods have cross-validation built right in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "We'll use the [IMDB movie review](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the charact...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is an example of why the majority of action films are the same. Generic and boring, there's really nothing worth watching here. A complete waste of the then barely-tapped talents of Ice-T and...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First of all I hate those moronic rappers, who could'nt act if they had a gun pressed against their foreheads. All they do is curse and shoot each other and acting like clichÃ©'e version of gangst...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not even the Beatles could write songs everyone liked, and although Walter Hill is no mop-top he's second to none when it comes to thought provoking action movies. The nineties came and social pla...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brass pictures (movies is not a fitting word for them) really are somewhat brassy. Their alluring visual qualities are reminiscent of expensive high class TV commercials. But unfortunately Brass p...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                    review  \\\n",
       "0  Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the charact...   \n",
       "1  This is an example of why the majority of action films are the same. Generic and boring, there's really nothing worth watching here. A complete waste of the then barely-tapped talents of Ice-T and...   \n",
       "2  First of all I hate those moronic rappers, who could'nt act if they had a gun pressed against their foreheads. All they do is curse and shoot each other and acting like clichÃ©'e version of gangst...   \n",
       "3  Not even the Beatles could write songs everyone liked, and although Walter Hill is no mop-top he's second to none when it comes to thought provoking action movies. The nineties came and social pla...   \n",
       "4  Brass pictures (movies is not a fitting word for them) really are somewhat brassy. Their alluring visual qualities are reminiscent of expensive high class TV commercials. But unfortunately Brass p...   \n",
       "\n",
       "  label  \n",
       "0   neg  \n",
       "1   neg  \n",
       "2   neg  \n",
       "3   neg  \n",
       "4   neg  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df = pd.read_csv(\"data/imdb_master.csv\", encoding=\"ISO-8859-1\")\n",
    "imdb_df = imdb_df[imdb_df[\"label\"].str.startswith((\"pos\", \"neg\"))]\n",
    "imdb_df.drop([\"Unnamed: 0\", \"type\", \"file\"], axis=1, inplace=True)\n",
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def replace_tags(doc):\n",
    "    doc = doc.replace(\"<br />\", \" \")\n",
    "    doc = re.sub(\"https://\\S*\", \"\", doc)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df[\"review_pp\"] = imdb_df[\"review\"].apply(replace_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(imdb_df, test_size=0.9, random_state=123)\n",
    "X_train, y_train = train_df[\"review_pp\"], train_df[\"label\"]\n",
    "X_test, y_test = test_df[\"review_pp\"], test_df[\"label\"]\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(stop_words=\"english\", max_features=5000)\n",
    "X_train_imdb = vec.fit_transform(X_train)\n",
    "X_test_imdb = vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Exhaustive grid search\n",
    "\n",
    "- A user specifies a set of values for each hyperparameter. \n",
    "- The method considers \"product\" of the sets and then evaluates each combination one by one.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start the automated hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"C\": [0.01, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "grid_search = GridSearchCV(lr, param_grid, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that we can fix some hyperparameters and make others variable.\n",
    "- `verbose=1` tells `GridSearchCV` to print some output while it's working.\n",
    "  - This can be useful as this step sometimes takes a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train_imdb, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to Lecture 3, this is what it's doing:\n",
    "\n",
    "```\n",
    "for C in [0.01, 1, 10, 100]:\n",
    "    for fold in folds:\n",
    "        fit in training portion with the given C\n",
    "        score on validation portion\n",
    "    compute average score\n",
    "pick hypers with best score\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can extract the best hyperparameter values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8474666666666668"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the classifier inside like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, max_iter=1000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pos', 'pos', 'pos', ..., 'pos', 'pos', 'pos'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.predict(X_test_imdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They also provide some \"syntactic sugar\" and allow you to call `predict` or `score` directly on the `GridSearchCV` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pos', 'pos', 'pos', ..., 'pos', 'pos', 'pos'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.predict(X_test_imdb)  ## Does the same thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way, by default it takes the best hyperparameters and refits on the entire training set - very nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `refit=True` to control this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ok, so this is all the syntax, but now we know we've been violating the Golden Rule because of the cross-validation.\n",
    "- Furthermore, we may want to tune the hyperparameters of the `CountVectorizer` and the `LogisticRegression` together.\n",
    "- Pipelines are perfect for this!!\n",
    "- So let's do it again properly this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "countvec = CountVectorizer(\n",
    "    binary=True\n",
    ")  # we should not set min_df here, it will be optimized\n",
    "lr = LogisticRegression(max_iter=1000)  # we should not set C here, it will be optimized\n",
    "\n",
    "pipe = Pipeline([(\"countvec\", countvec), (\"lr\", lr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"countvec__min_df\": [0, 10, 100], \"lr__C\": [0.01, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above: we have a nesting of transformers. \n",
    "- We can access the parameters of the \"inner\" objects by using `__` to go \"deeper\":\n",
    "  - `countvec__min_df`: \"the `min_df` of the `CountVectorizer` (of the pipeline)\"\n",
    "  - `lr__C`: \"the `C` of the `LogisticRegression` (of the pipeline)\"\n",
    "- Later in the course we'll see even deeper nesting, like `preprocessor__numeric__imputer__strategy`.\n",
    "\n",
    "So, now we pass int he `Pipeline` to `GridSearchCV`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipe, param_grid, verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we pass in the raw text because we're using a `Pipeline`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   44.0s finished\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train_imdb_raw, y_train_imdb);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note the `n_jobs=-1` above.\n",
    "- Hyperparameter optimization can be done _in parallel_ for each of the configurations.\n",
    "- This is very useful when scaling up to large numbers of machines in the cloud.\n",
    "- But even on my laptop there are 8 cores it can use, so that makes it a lot faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvec__min_df': 0, 'lr__C': 1}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heh, here we get back the defaults again. This happens surprisingly often - the defaults are well chosen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note the number of candidates comes from the **product** of the number of options for each hyperparameter.\n",
    "- And then the whole thing multiplied by the number of folds (default is 5).\n",
    "- So, this number can get big really fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But note that we're searching more possibilities than if we just sweep one hyperparameter at a time:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/gridsearch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that case we'd only get the ones in red, but here we get the entire grid.\n",
    "\n",
    "(Img source: see credit below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Problems with exhaustive grid search \n",
    "\n",
    "- Required number of models to evaluate grows exponentially with the dimensionally of the configuration space. \n",
    "- Exhaustive search may become infeasible fairly quickly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data \n",
    "\n",
    "We'll be using [the adult census dataset](https://www.kaggle.com/uciml/adult-census-income#) you used in lab 2. \n",
    "\n",
    "This is a classification dataset and the classification task is to predict whether income exceeds 50K per year or not based on the census data. You can find more information on the dataset and features [here](http://archive.ics.uci.edu/ml/datasets/Adult).\n",
    "\n",
    "The code below loads the data CSV (assuming that it is saved as `data/adult.csv` in this folder). \n",
    "\n",
    "*Note that many popular datasets have sex as a feature where the possible values are male and female. This representation reflects how the data were collected and is not meant to imply that, for example, gender is binary.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reading the data CSV and splitting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "adult_df_large = pd.read_csv(\"data/adult.csv\")\n",
    "adult_df_sample = adult_df_large.sample(frac=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(adult_df_sample, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "train_df_nan = train_df.replace(\"?\", np.NaN)\n",
    "test_df_nan = test_df.replace(\"?\", np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19258</th>\n",
       "      <td>23</td>\n",
       "      <td>Private</td>\n",
       "      <td>237044</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9782</th>\n",
       "      <td>35</td>\n",
       "      <td>Private</td>\n",
       "      <td>38948</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>46</td>\n",
       "      <td>Private</td>\n",
       "      <td>155659</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29224</th>\n",
       "      <td>42</td>\n",
       "      <td>Private</td>\n",
       "      <td>126003</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16985</th>\n",
       "      <td>38</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>114835</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt     education  education.num  \\\n",
       "19258   23           Private  237044       HS-grad              9   \n",
       "9782    35           Private   38948  Some-college             10   \n",
       "1842    46           Private  155659  Some-college             10   \n",
       "29224   42           Private  126003       HS-grad              9   \n",
       "16985   38  Self-emp-not-inc  114835     Bachelors             13   \n",
       "\n",
       "           marital.status      occupation relationship   race     sex  \\\n",
       "19258       Never-married   Other-service    Own-child  Black    Male   \n",
       "9782   Married-civ-spouse  Prof-specialty      Husband  White    Male   \n",
       "1842   Married-civ-spouse    Craft-repair      Husband  White    Male   \n",
       "29224  Married-civ-spouse    Tech-support      Husband  White    Male   \n",
       "16985  Married-civ-spouse           Sales         Wife  White  Female   \n",
       "\n",
       "       capital.gain  capital.loss  hours.per.week native.country income  \n",
       "19258             0             0              12  United-States  <=50K  \n",
       "9782              0             0              40  United-States   >50K  \n",
       "1842          15024             0              45  United-States   >50K  \n",
       "29224             0             0              40  United-States   >50K  \n",
       "16985             0             0              60  United-States   >50K  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_nan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<=50K    5914\n",
       ">50K     1900\n",
       "Name: income, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_nan[\"income\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Identify feature types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "numeric_features = [\"age\", \"fnlwgt\", \"capital.gain\", \"capital.loss\", \"hours.per.week\"]\n",
    "# I am removing eduction.num column\n",
    "categorical_features = [\n",
    "    \"workclass\",\n",
    "    \"marital.status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"sex\",\n",
    "    \"native.country\",\n",
    "]\n",
    "# I am removing 'race' column\n",
    "ordinal_features = [\"education\"]\n",
    "target = \"income\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_levels = [\n",
    "    \"Preschool\",\n",
    "    \"1st-4th\",\n",
    "    \"5th-6th\",\n",
    "    \"7th-8th\",\n",
    "    \"9th\",\n",
    "    \"10th\",\n",
    "    \"11th\",\n",
    "    \"12th\",\n",
    "    \"HS-grad\",\n",
    "    \"Prof-school\",\n",
    "    \"Assoc-voc\",\n",
    "    \"Assoc-acdm\",\n",
    "    \"Some-college\",\n",
    "    \"Bachelors\",\n",
    "    \"Masters\",\n",
    "    \"Doctorate\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(education_levels) == set(train_df[\"education\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df_nan.drop(columns=[target])\n",
    "y_train = train_df_nan[target]\n",
    "\n",
    "X_test = test_df_nan.drop(columns=[target])\n",
    "y_test = test_df_nan[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Define `ColumnTransformer` and a pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler())\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"),\n",
    ")\n",
    "\n",
    "ordinal_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "    OrdinalEncoder(\n",
    "        categories=[education_levels],\n",
    "        dtype=int,\n",
    "    ),\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "        (\"ordinal\", ordinal_transformer, ordinal_features),\n",
    "    ]\n",
    ")\n",
    "pipe = make_pipeline(preprocessor, SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "scores = cross_validate(pipe, X_train, y_train, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.619898\n",
       "score_time     0.113588\n",
       "test_score     0.846430\n",
       "train_score    0.848861\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- We are using the default hyperparameters for SVC. \n",
    "- We have cherry picked hyperparameters for some of our transformers.  \n",
    "- Probably we could do better with different hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's carry out hyperparameter optimization with `C` and `gamma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Writing a loop for hyperparameter optimization for gamma and C for SVC\n",
    "param_grid = {\"gamma\": [0.1, 1.0, 10, 100], \"C\": [0.1, 1.0, 10, 100]}\n",
    "\n",
    "param_scores = {\"gamma\": [], \"C\": [], \"train_accuracy\": [], \"valid_accuracy\": []}\n",
    "for gamma_val in param_grid[\"gamma\"]:\n",
    "    for c_val in param_grid[\"C\"]:\n",
    "        pipe = make_pipeline(preprocessor, SVC(gamma=gamma_val, C=c_val))\n",
    "        scores = cross_validate(pipe, X_train, y_train, cv=5, return_train_score=True)\n",
    "        param_scores[\"gamma\"].append(gamma_val)\n",
    "        param_scores[\"C\"].append(c_val)\n",
    "        param_scores[\"train_accuracy\"].append(np.mean(scores[\"train_score\"]))\n",
    "        param_scores[\"valid_accuracy\"].append(np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>C</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.872728</td>\n",
       "      <td>0.852444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.916048</td>\n",
       "      <td>0.845406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.839615</td>\n",
       "      <td>0.832480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.949898</td>\n",
       "      <td>0.810981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957384</td>\n",
       "      <td>0.791401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.984419</td>\n",
       "      <td>0.783593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.994081</td>\n",
       "      <td>0.778601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.765357</td>\n",
       "      <td>0.763117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989890</td>\n",
       "      <td>0.758766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.998432</td>\n",
       "      <td>0.757999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.999616</td>\n",
       "      <td>0.757743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.756847</td>\n",
       "      <td>0.756847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.756847</td>\n",
       "      <td>0.756847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998240</td>\n",
       "      <td>0.756719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>0.756591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.756591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gamma      C  train_accuracy  valid_accuracy\n",
       "1     0.1    1.0        0.872728        0.852444\n",
       "2     0.1   10.0        0.916048        0.845406\n",
       "0     0.1    0.1        0.839615        0.832480\n",
       "3     0.1  100.0        0.949898        0.810981\n",
       "5     1.0    1.0        0.957384        0.791401\n",
       "6     1.0   10.0        0.984419        0.783593\n",
       "7     1.0  100.0        0.994081        0.778601\n",
       "4     1.0    0.1        0.765357        0.763117\n",
       "9    10.0    1.0        0.989890        0.758766\n",
       "10   10.0   10.0        0.998432        0.757999\n",
       "11   10.0  100.0        0.999616        0.757743\n",
       "8    10.0    0.1        0.756847        0.756847\n",
       "12  100.0    0.1        0.756847        0.756847\n",
       "13  100.0    1.0        0.998240        0.756719\n",
       "14  100.0   10.0        0.999680        0.756591\n",
       "15  100.0  100.0        1.000000        0.756591"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(param_scores).sort_values(\"valid_accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Questions and comments \n",
    "\n",
    "- How many 5-fold cross-validation experiments are carried out here? \n",
    "- How would it work with more hyperparameters? \n",
    "- Remember that we also have hyperparameters of our transformers. For example, you might want to try \"mean\" or \"median\" strategies for your scaler and pick the one that works best. \n",
    "- If you want to try multiple classifiers each with a different set of hyperparameters\n",
    "- Writing for loops for this and keeping track of all scores becomes unwieldy quite quickly! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Automated hyperparameter tuning: the solution?\n",
    "\n",
    "- Advantage: reduce human effort\n",
    "- Advantage: less prone to error and improve reproducibility\n",
    "- Advantage: data-driven approaches may be effective\n",
    "- Disadvantage: may be hard to incorporate intuition\n",
    "- Disadvantage: be careful about overfitting on the validation set (We'll talk about it in the second part.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `scikit-learn` built-in methods for hyperparameter optimization\n",
    "\n",
    "`scikit-learn` has the following [built-in methods](https://scikit-learn.org/stable/modules/grid_search.html) which automate hyperparameter optimization for you. \n",
    "\n",
    "1. Exhaustive grid search \n",
    "    - [`sklearn.model_selection.GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "2. Randomized hyperparameter optimization \n",
    "    - [`sklearn.model_selection.RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exhaustive grid search\n",
    "\n",
    "- [`sklearn.model_selection.GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "\n",
    "- How does it work? \n",
    "    - A user specifies a set of values for each hyperparameter. \n",
    "    - The method considers product of the sets and then evaluates each combination one by one.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.59 s, sys: 229 ms, total: 1.82 s\n",
      "Wall time: 31.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('columntransformer',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('simpleimputer',\n",
       "                                                                                          SimpleImputer(strategy='median')),\n",
       "                                                                                         ('standardscaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['age',\n",
       "                                                                          'fnlwgt',\n",
       "                                                                          'capital.gain',\n",
       "                                                                          'capital.loss',\n",
       "                                                                          'hours.per.week']),\n",
       "                                                                        ('cat',\n",
       "                                                                         Pipeline(steps=[('simpleimputer',\n",
       "                                                                                          SimpleImputer(fill_value='missing',\n",
       "                                                                                                        s...\n",
       "                                                                                          OrdinalEncoder(categories=[['Preschool',\n",
       "                                                                                                                      '1st-4th',\n",
       "                                                                                                                      '5th-6th',\n",
       "                                                                                                                      '7th-8th',\n",
       "                                                                                                                      '9th',\n",
       "                                                                                                                      '10th',\n",
       "                                                                                                                      '11th',\n",
       "                                                                                                                      '12th',\n",
       "                                                                                                                      'HS-grad',\n",
       "                                                                                                                      'Prof-school',\n",
       "                                                                                                                      'Assoc-voc',\n",
       "                                                                                                                      'Assoc-acdm',\n",
       "                                                                                                                      'Some-college',\n",
       "                                                                                                                      'Bachelors',\n",
       "                                                                                                                      'Masters',\n",
       "                                                                                                                      'Doctorate']],\n",
       "                                                                                                         dtype=<class 'int'>))]),\n",
       "                                                                         ['education'])])),\n",
       "                                       ('svc', SVC(C=100, gamma=100))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'svc__C': [0.1, 1.0, 10, 100],\n",
       "                         'svc__gamma': [0.1, 1.0, 10, 100]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"svc__gamma\": [0.1, 1.0, 10, 100],\n",
    "    \"svc__C\": [0.1, 1.0, 10, 100],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cv score from grid search: 0.852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'svc__C': 1.0, 'svc__gamma': 0.1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best cv score from grid search: %.3f\" % grid_search.best_score_)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_svc__C</th>\n",
       "      <th>param_svc__gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.908747</td>\n",
       "      <td>0.016357</td>\n",
       "      <td>0.204031</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'svc__C': 1.0, 'svc__gamma': 0.1}</td>\n",
       "      <td>0.842610</td>\n",
       "      <td>0.859245</td>\n",
       "      <td>0.859885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851472</td>\n",
       "      <td>0.852444</td>\n",
       "      <td>0.006497</td>\n",
       "      <td>0.874740</td>\n",
       "      <td>0.872820</td>\n",
       "      <td>0.870261</td>\n",
       "      <td>0.874420</td>\n",
       "      <td>0.871401</td>\n",
       "      <td>0.872728</td>\n",
       "      <td>0.001719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.748669</td>\n",
       "      <td>0.037835</td>\n",
       "      <td>0.195921</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'svc__C': 10, 'svc__gamma': 0.1}</td>\n",
       "      <td>0.840051</td>\n",
       "      <td>0.854766</td>\n",
       "      <td>0.849008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845711</td>\n",
       "      <td>0.845406</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>0.918733</td>\n",
       "      <td>0.913614</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.916493</td>\n",
       "      <td>0.916507</td>\n",
       "      <td>0.916048</td>\n",
       "      <td>0.001725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.926996</td>\n",
       "      <td>0.059028</td>\n",
       "      <td>0.265295</td>\n",
       "      <td>0.013773</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'svc__C': 0.1, 'svc__gamma': 0.1}</td>\n",
       "      <td>0.820857</td>\n",
       "      <td>0.834933</td>\n",
       "      <td>0.843890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834187</td>\n",
       "      <td>0.832480</td>\n",
       "      <td>0.007613</td>\n",
       "      <td>0.844345</td>\n",
       "      <td>0.837946</td>\n",
       "      <td>0.836826</td>\n",
       "      <td>0.838746</td>\n",
       "      <td>0.840211</td>\n",
       "      <td>0.839615</td>\n",
       "      <td>0.002609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.166481</td>\n",
       "      <td>0.121645</td>\n",
       "      <td>0.194305</td>\n",
       "      <td>0.005071</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'svc__C': 100, 'svc__gamma': 0.1}</td>\n",
       "      <td>0.815099</td>\n",
       "      <td>0.818938</td>\n",
       "      <td>0.813820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816261</td>\n",
       "      <td>0.810981</td>\n",
       "      <td>0.010237</td>\n",
       "      <td>0.950088</td>\n",
       "      <td>0.948808</td>\n",
       "      <td>0.948488</td>\n",
       "      <td>0.952488</td>\n",
       "      <td>0.949616</td>\n",
       "      <td>0.949898</td>\n",
       "      <td>0.001414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.088506</td>\n",
       "      <td>0.147284</td>\n",
       "      <td>0.441413</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'svc__C': 1.0, 'svc__gamma': 1.0}</td>\n",
       "      <td>0.789507</td>\n",
       "      <td>0.796545</td>\n",
       "      <td>0.804862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797695</td>\n",
       "      <td>0.791401</td>\n",
       "      <td>0.012492</td>\n",
       "      <td>0.957287</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.956327</td>\n",
       "      <td>0.958727</td>\n",
       "      <td>0.957134</td>\n",
       "      <td>0.957384</td>\n",
       "      <td>0.000774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.591746</td>\n",
       "      <td>0.553660</td>\n",
       "      <td>0.551825</td>\n",
       "      <td>0.058971</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'svc__C': 10, 'svc__gamma': 1.0}</td>\n",
       "      <td>0.777351</td>\n",
       "      <td>0.795905</td>\n",
       "      <td>0.792706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775928</td>\n",
       "      <td>0.783593</td>\n",
       "      <td>0.008820</td>\n",
       "      <td>0.984163</td>\n",
       "      <td>0.983843</td>\n",
       "      <td>0.984642</td>\n",
       "      <td>0.984482</td>\n",
       "      <td>0.984965</td>\n",
       "      <td>0.984419</td>\n",
       "      <td>0.000387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.143064</td>\n",
       "      <td>0.519868</td>\n",
       "      <td>0.353574</td>\n",
       "      <td>0.008612</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'svc__C': 100, 'svc__gamma': 1.0}</td>\n",
       "      <td>0.773512</td>\n",
       "      <td>0.798464</td>\n",
       "      <td>0.780550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765045</td>\n",
       "      <td>0.778601</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.993921</td>\n",
       "      <td>0.993121</td>\n",
       "      <td>0.994561</td>\n",
       "      <td>0.994561</td>\n",
       "      <td>0.994242</td>\n",
       "      <td>0.994081</td>\n",
       "      <td>0.000535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.105062</td>\n",
       "      <td>0.200283</td>\n",
       "      <td>0.591333</td>\n",
       "      <td>0.052098</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'svc__C': 0.1, 'svc__gamma': 1.0}</td>\n",
       "      <td>0.763916</td>\n",
       "      <td>0.762636</td>\n",
       "      <td>0.764555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.762484</td>\n",
       "      <td>0.763117</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.766597</td>\n",
       "      <td>0.765318</td>\n",
       "      <td>0.763718</td>\n",
       "      <td>0.765797</td>\n",
       "      <td>0.765355</td>\n",
       "      <td>0.765357</td>\n",
       "      <td>0.000940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.050587</td>\n",
       "      <td>0.091293</td>\n",
       "      <td>0.584451</td>\n",
       "      <td>0.032579</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'svc__C': 1.0, 'svc__gamma': 10}</td>\n",
       "      <td>0.760717</td>\n",
       "      <td>0.756878</td>\n",
       "      <td>0.760077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758003</td>\n",
       "      <td>0.758766</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.989922</td>\n",
       "      <td>0.989122</td>\n",
       "      <td>0.990082</td>\n",
       "      <td>0.989282</td>\n",
       "      <td>0.991043</td>\n",
       "      <td>0.989890</td>\n",
       "      <td>0.000682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.305142</td>\n",
       "      <td>0.059122</td>\n",
       "      <td>0.554369</td>\n",
       "      <td>0.016215</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'svc__C': 10, 'svc__gamma': 10}</td>\n",
       "      <td>0.760077</td>\n",
       "      <td>0.752399</td>\n",
       "      <td>0.758157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761204</td>\n",
       "      <td>0.757999</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.998400</td>\n",
       "      <td>0.998240</td>\n",
       "      <td>0.998880</td>\n",
       "      <td>0.998080</td>\n",
       "      <td>0.998560</td>\n",
       "      <td>0.998432</td>\n",
       "      <td>0.000275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.073205</td>\n",
       "      <td>0.028526</td>\n",
       "      <td>0.447852</td>\n",
       "      <td>0.009148</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'svc__C': 100, 'svc__gamma': 10}</td>\n",
       "      <td>0.760717</td>\n",
       "      <td>0.752399</td>\n",
       "      <td>0.758157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759923</td>\n",
       "      <td>0.757743</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>0.999360</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>0.999616</td>\n",
       "      <td>0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.462002</td>\n",
       "      <td>0.073579</td>\n",
       "      <td>0.840595</td>\n",
       "      <td>0.015886</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'svc__C': 0.1, 'svc__gamma': 10}</td>\n",
       "      <td>0.756878</td>\n",
       "      <td>0.756878</td>\n",
       "      <td>0.756878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756722</td>\n",
       "      <td>0.756847</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.756839</td>\n",
       "      <td>0.756839</td>\n",
       "      <td>0.756839</td>\n",
       "      <td>0.756839</td>\n",
       "      <td>0.756878</td>\n",
       "      <td>0.756847</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.836406</td>\n",
       "      <td>0.118449</td>\n",
       "      <td>0.742922</td>\n",
       "      <td>0.064156</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'svc__C': 0.1, 'svc__gamma': 100}</td>\n",
       "      <td>0.756878</td>\n",
       "      <td>0.756878</td>\n",
       "      <td>0.756878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756722</td>\n",
       "      <td>0.756847</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.756839</td>\n",
       "      <td>0.756839</td>\n",
       "      <td>0.756839</td>\n",
       "      <td>0.756839</td>\n",
       "      <td>0.756878</td>\n",
       "      <td>0.756847</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.710889</td>\n",
       "      <td>0.059277</td>\n",
       "      <td>0.500462</td>\n",
       "      <td>0.022772</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'svc__C': 1.0, 'svc__gamma': 100}</td>\n",
       "      <td>0.755598</td>\n",
       "      <td>0.757518</td>\n",
       "      <td>0.756878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756722</td>\n",
       "      <td>0.756719</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.998080</td>\n",
       "      <td>0.998240</td>\n",
       "      <td>0.998720</td>\n",
       "      <td>0.997920</td>\n",
       "      <td>0.998241</td>\n",
       "      <td>0.998240</td>\n",
       "      <td>0.000268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.558117</td>\n",
       "      <td>0.098283</td>\n",
       "      <td>0.516642</td>\n",
       "      <td>0.014235</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'svc__C': 10, 'svc__gamma': 100}</td>\n",
       "      <td>0.756878</td>\n",
       "      <td>0.756878</td>\n",
       "      <td>0.756878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756082</td>\n",
       "      <td>0.756591</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.999840</td>\n",
       "      <td>0.999520</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>0.000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.081595</td>\n",
       "      <td>0.115879</td>\n",
       "      <td>0.411206</td>\n",
       "      <td>0.010108</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'svc__C': 100, 'svc__gamma': 100}</td>\n",
       "      <td>0.756878</td>\n",
       "      <td>0.756878</td>\n",
       "      <td>0.756878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756082</td>\n",
       "      <td>0.756591</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "rank_test_score                                                                 \n",
       "1                     1.908747      0.016357         0.204031        0.003334   \n",
       "2                     2.748669      0.037835         0.195921        0.002304   \n",
       "3                     2.926996      0.059028         0.265295        0.013773   \n",
       "4                     4.166481      0.121645         0.194305        0.005071   \n",
       "5                     5.088506      0.147284         0.441413        0.010283   \n",
       "6                     5.591746      0.553660         0.551825        0.058971   \n",
       "7                     5.143064      0.519868         0.353574        0.008612   \n",
       "8                     5.105062      0.200283         0.591333        0.052098   \n",
       "9                     5.050587      0.091293         0.584451        0.032579   \n",
       "10                    5.305142      0.059122         0.554369        0.016215   \n",
       "11                    4.073205      0.028526         0.447852        0.009148   \n",
       "12                    5.462002      0.073579         0.840595        0.015886   \n",
       "12                    4.836406      0.118449         0.742922        0.064156   \n",
       "14                    4.710889      0.059277         0.500462        0.022772   \n",
       "15                    4.558117      0.098283         0.516642        0.014235   \n",
       "15                    3.081595      0.115879         0.411206        0.010108   \n",
       "\n",
       "                param_svc__C param_svc__gamma  \\\n",
       "rank_test_score                                 \n",
       "1                          1              0.1   \n",
       "2                         10              0.1   \n",
       "3                        0.1              0.1   \n",
       "4                        100              0.1   \n",
       "5                          1                1   \n",
       "6                         10                1   \n",
       "7                        100                1   \n",
       "8                        0.1                1   \n",
       "9                          1               10   \n",
       "10                        10               10   \n",
       "11                       100               10   \n",
       "12                       0.1               10   \n",
       "12                       0.1              100   \n",
       "14                         1              100   \n",
       "15                        10              100   \n",
       "15                       100              100   \n",
       "\n",
       "                                             params  split0_test_score  \\\n",
       "rank_test_score                                                          \n",
       "1                {'svc__C': 1.0, 'svc__gamma': 0.1}           0.842610   \n",
       "2                 {'svc__C': 10, 'svc__gamma': 0.1}           0.840051   \n",
       "3                {'svc__C': 0.1, 'svc__gamma': 0.1}           0.820857   \n",
       "4                {'svc__C': 100, 'svc__gamma': 0.1}           0.815099   \n",
       "5                {'svc__C': 1.0, 'svc__gamma': 1.0}           0.789507   \n",
       "6                 {'svc__C': 10, 'svc__gamma': 1.0}           0.777351   \n",
       "7                {'svc__C': 100, 'svc__gamma': 1.0}           0.773512   \n",
       "8                {'svc__C': 0.1, 'svc__gamma': 1.0}           0.763916   \n",
       "9                 {'svc__C': 1.0, 'svc__gamma': 10}           0.760717   \n",
       "10                 {'svc__C': 10, 'svc__gamma': 10}           0.760077   \n",
       "11                {'svc__C': 100, 'svc__gamma': 10}           0.760717   \n",
       "12                {'svc__C': 0.1, 'svc__gamma': 10}           0.756878   \n",
       "12               {'svc__C': 0.1, 'svc__gamma': 100}           0.756878   \n",
       "14               {'svc__C': 1.0, 'svc__gamma': 100}           0.755598   \n",
       "15                {'svc__C': 10, 'svc__gamma': 100}           0.756878   \n",
       "15               {'svc__C': 100, 'svc__gamma': 100}           0.756878   \n",
       "\n",
       "                 split1_test_score  split2_test_score  ...  split4_test_score  \\\n",
       "rank_test_score                                        ...                      \n",
       "1                         0.859245           0.859885  ...           0.851472   \n",
       "2                         0.854766           0.849008  ...           0.845711   \n",
       "3                         0.834933           0.843890  ...           0.834187   \n",
       "4                         0.818938           0.813820  ...           0.816261   \n",
       "5                         0.796545           0.804862  ...           0.797695   \n",
       "6                         0.795905           0.792706  ...           0.775928   \n",
       "7                         0.798464           0.780550  ...           0.765045   \n",
       "8                         0.762636           0.764555  ...           0.762484   \n",
       "9                         0.756878           0.760077  ...           0.758003   \n",
       "10                        0.752399           0.758157  ...           0.761204   \n",
       "11                        0.752399           0.758157  ...           0.759923   \n",
       "12                        0.756878           0.756878  ...           0.756722   \n",
       "12                        0.756878           0.756878  ...           0.756722   \n",
       "14                        0.757518           0.756878  ...           0.756722   \n",
       "15                        0.756878           0.756878  ...           0.756082   \n",
       "15                        0.756878           0.756878  ...           0.756082   \n",
       "\n",
       "                 mean_test_score  std_test_score  split0_train_score  \\\n",
       "rank_test_score                                                        \n",
       "1                       0.852444        0.006497            0.874740   \n",
       "2                       0.845406        0.006197            0.918733   \n",
       "3                       0.832480        0.007613            0.844345   \n",
       "4                       0.810981        0.010237            0.950088   \n",
       "5                       0.791401        0.012492            0.957287   \n",
       "6                       0.783593        0.008820            0.984163   \n",
       "7                       0.778601        0.011118            0.993921   \n",
       "8                       0.763117        0.000959            0.766597   \n",
       "9                       0.758766        0.001417            0.989922   \n",
       "10                      0.757999        0.003033            0.998400   \n",
       "11                      0.757743        0.002911            0.999680   \n",
       "12                      0.756847        0.000062            0.756839   \n",
       "12                      0.756847        0.000062            0.756839   \n",
       "14                      0.756719        0.000624            0.998080   \n",
       "15                      0.756591        0.000355            0.999840   \n",
       "15                      0.756591        0.000355            1.000000   \n",
       "\n",
       "                 split1_train_score  split2_train_score  split3_train_score  \\\n",
       "rank_test_score                                                               \n",
       "1                          0.872820            0.870261            0.874420   \n",
       "2                          0.913614            0.914894            0.916493   \n",
       "3                          0.837946            0.836826            0.838746   \n",
       "4                          0.948808            0.948488            0.952488   \n",
       "5                          0.957447            0.956327            0.958727   \n",
       "6                          0.983843            0.984642            0.984482   \n",
       "7                          0.993121            0.994561            0.994561   \n",
       "8                          0.765318            0.763718            0.765797   \n",
       "9                          0.989122            0.990082            0.989282   \n",
       "10                         0.998240            0.998880            0.998080   \n",
       "11                         0.999360            0.999680            0.999680   \n",
       "12                         0.756839            0.756839            0.756839   \n",
       "12                         0.756839            0.756839            0.756839   \n",
       "14                         0.998240            0.998720            0.997920   \n",
       "15                         0.999520            0.999680            0.999680   \n",
       "15                         1.000000            1.000000            1.000000   \n",
       "\n",
       "                 split4_train_score  mean_train_score  std_train_score  \n",
       "rank_test_score                                                         \n",
       "1                          0.871401          0.872728         0.001719  \n",
       "2                          0.916507          0.916048         0.001725  \n",
       "3                          0.840211          0.839615         0.002609  \n",
       "4                          0.949616          0.949898         0.001414  \n",
       "5                          0.957134          0.957384         0.000774  \n",
       "6                          0.984965          0.984419         0.000387  \n",
       "7                          0.994242          0.994081         0.000535  \n",
       "8                          0.765355          0.765357         0.000940  \n",
       "9                          0.991043          0.989890         0.000682  \n",
       "10                         0.998560          0.998432         0.000275  \n",
       "11                         0.999680          0.999616         0.000128  \n",
       "12                         0.756878          0.756847         0.000016  \n",
       "12                         0.756878          0.756847         0.000016  \n",
       "14                         0.998241          0.998240         0.000268  \n",
       "15                         0.999680          0.999680         0.000101  \n",
       "15                         1.000000          1.000000         0.000000  \n",
       "\n",
       "[16 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_).set_index(\"rank_test_score\").sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `__` syntax \n",
    "\n",
    "- Above: we have a nesting of transformers.\n",
    "- We can access the parameters of the \"inner\" objects by using __ to go \"deeper\":\n",
    "- `svc__gamma`: the `gamma` of the `svc` of the pipeline\n",
    "- `svc__C`: the `C` of the `svc` of the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How do we access hyperparameters of transformers\n",
    "\n",
    "- `columntransformer__num__simpleimputer__strategy`: the strategy used with `SimpleImputer` of the preprocessor in the pipeline. \n",
    "Later in the course we'll see even deeper nesting, like preprocessor__numeric__imputer__strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('simpleimputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('standardscaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['age', 'fnlwgt',\n",
       "                                                   'capital.gain',\n",
       "                                                   'capital.loss',\n",
       "                                                   'hours.per.week']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('simpleimputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('oneho...\n",
       "                                                  Pipeline(steps=[('simpleimputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('ordinalencoder',\n",
       "                                                                   OrdinalEncoder(categories=[['Preschool',\n",
       "                                                                                               '1st-4th',\n",
       "                                                                                               '5th-6th',\n",
       "                                                                                               '7th-8th',\n",
       "                                                                                               '9th',\n",
       "                                                                                               '10th',\n",
       "                                                                                               '11th',\n",
       "                                                                                               '12th',\n",
       "                                                                                               'HS-grad',\n",
       "                                                                                               'Prof-school',\n",
       "                                                                                               'Assoc-voc',\n",
       "                                                                                               'Assoc-acdm',\n",
       "                                                                                               'Some-college',\n",
       "                                                                                               'Bachelors',\n",
       "                                                                                               'Masters',\n",
       "                                                                                               'Doctorate']],\n",
       "                                                                                  dtype=<class 'int'>))]),\n",
       "                                                  ['education'])])),\n",
       "                ('svc', SVC(C=100, gamma=100))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"svc__gamma\": [0.1, 1.0],\n",
    "    \"columntransformer__num__simpleimputer__strategy\": [\"mean\", \"median\"],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVC from grid search: 0.814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_columntransformer__num__simpleimputer__strategy</th>\n",
       "      <th>param_svc__gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.369722</td>\n",
       "      <td>0.073645</td>\n",
       "      <td>0.187483</td>\n",
       "      <td>0.002374</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'columntransformer__num__simpleimputer__strategy': 'mean', 'svc__gamma': 0.1}</td>\n",
       "      <td>0.815099</td>\n",
       "      <td>0.818938</td>\n",
       "      <td>0.81382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810981</td>\n",
       "      <td>0.010237</td>\n",
       "      <td>1</td>\n",
       "      <td>0.950088</td>\n",
       "      <td>0.948808</td>\n",
       "      <td>0.948488</td>\n",
       "      <td>0.952488</td>\n",
       "      <td>0.949616</td>\n",
       "      <td>0.949898</td>\n",
       "      <td>0.001414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.416549</td>\n",
       "      <td>0.066688</td>\n",
       "      <td>0.186616</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>median</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'columntransformer__num__simpleimputer__strategy': 'median', 'svc__gamma': 0.1}</td>\n",
       "      <td>0.815099</td>\n",
       "      <td>0.818938</td>\n",
       "      <td>0.81382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810981</td>\n",
       "      <td>0.010237</td>\n",
       "      <td>1</td>\n",
       "      <td>0.950088</td>\n",
       "      <td>0.948808</td>\n",
       "      <td>0.948488</td>\n",
       "      <td>0.952488</td>\n",
       "      <td>0.949616</td>\n",
       "      <td>0.949898</td>\n",
       "      <td>0.001414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.850827</td>\n",
       "      <td>0.385002</td>\n",
       "      <td>0.276416</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>mean</td>\n",
       "      <td>1</td>\n",
       "      <td>{'columntransformer__num__simpleimputer__strategy': 'mean', 'svc__gamma': 1.0}</td>\n",
       "      <td>0.773512</td>\n",
       "      <td>0.798464</td>\n",
       "      <td>0.78055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778601</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>3</td>\n",
       "      <td>0.993921</td>\n",
       "      <td>0.993121</td>\n",
       "      <td>0.994561</td>\n",
       "      <td>0.994561</td>\n",
       "      <td>0.994242</td>\n",
       "      <td>0.994081</td>\n",
       "      <td>0.000535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.791268</td>\n",
       "      <td>0.403897</td>\n",
       "      <td>0.277448</td>\n",
       "      <td>0.007326</td>\n",
       "      <td>median</td>\n",
       "      <td>1</td>\n",
       "      <td>{'columntransformer__num__simpleimputer__strategy': 'median', 'svc__gamma': 1.0}</td>\n",
       "      <td>0.773512</td>\n",
       "      <td>0.798464</td>\n",
       "      <td>0.78055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778601</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>3</td>\n",
       "      <td>0.993921</td>\n",
       "      <td>0.993121</td>\n",
       "      <td>0.994561</td>\n",
       "      <td>0.994561</td>\n",
       "      <td>0.994242</td>\n",
       "      <td>0.994081</td>\n",
       "      <td>0.000535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       4.369722      0.073645         0.187483        0.002374   \n",
       "2       4.416549      0.066688         0.186616        0.001750   \n",
       "1       5.850827      0.385002         0.276416        0.006900   \n",
       "3       5.791268      0.403897         0.277448        0.007326   \n",
       "\n",
       "  param_columntransformer__num__simpleimputer__strategy param_svc__gamma  \\\n",
       "0                                                  mean              0.1   \n",
       "2                                                median              0.1   \n",
       "1                                                  mean                1   \n",
       "3                                                median                1   \n",
       "\n",
       "                                                                             params  \\\n",
       "0    {'columntransformer__num__simpleimputer__strategy': 'mean', 'svc__gamma': 0.1}   \n",
       "2  {'columntransformer__num__simpleimputer__strategy': 'median', 'svc__gamma': 0.1}   \n",
       "1    {'columntransformer__num__simpleimputer__strategy': 'mean', 'svc__gamma': 1.0}   \n",
       "3  {'columntransformer__num__simpleimputer__strategy': 'median', 'svc__gamma': 1.0}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  ...  \\\n",
       "0           0.815099           0.818938            0.81382  ...   \n",
       "2           0.815099           0.818938            0.81382  ...   \n",
       "1           0.773512           0.798464            0.78055  ...   \n",
       "3           0.773512           0.798464            0.78055  ...   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.810981        0.010237                1            0.950088   \n",
       "2         0.810981        0.010237                1            0.950088   \n",
       "1         0.778601        0.011118                3            0.993921   \n",
       "3         0.778601        0.011118                3            0.993921   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.948808            0.948488            0.952488   \n",
       "2            0.948808            0.948488            0.952488   \n",
       "1            0.993121            0.994561            0.994561   \n",
       "3            0.993121            0.994561            0.994561   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.949616          0.949898         0.001414  \n",
       "2            0.949616          0.949898         0.001414  \n",
       "1            0.994242          0.994081         0.000535  \n",
       "3            0.994242          0.994081         0.000535  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((\"Best SVC from grid search: %.3f\" % grid_search.score(X_test, y_test)))\n",
    "grid_search.best_params_\n",
    "pd.DataFrame(grid_search.cv_results_).sort_values(\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_columntransformer__num__simpleimputer__strategy</th>\n",
       "      <th>param_svc__gamma</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.810981</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.369722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.810981</td>\n",
       "      <td>median</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.416549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.778601</td>\n",
       "      <td>mean</td>\n",
       "      <td>1</td>\n",
       "      <td>5.850827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.778601</td>\n",
       "      <td>median</td>\n",
       "      <td>1</td>\n",
       "      <td>5.791268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean_test_score  \\\n",
       "rank_test_score                    \n",
       "1                       0.810981   \n",
       "1                       0.810981   \n",
       "3                       0.778601   \n",
       "3                       0.778601   \n",
       "\n",
       "                param_columntransformer__num__simpleimputer__strategy  \\\n",
       "rank_test_score                                                         \n",
       "1                                                                mean   \n",
       "1                                                              median   \n",
       "3                                                                mean   \n",
       "3                                                              median   \n",
       "\n",
       "                param_svc__gamma  mean_fit_time  \n",
       "rank_test_score                                  \n",
       "1                            0.1       4.369722  \n",
       "1                            0.1       4.416549  \n",
       "3                              1       5.850827  \n",
       "3                              1       5.791268  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)[\n",
    "    [\n",
    "        \"mean_test_score\",\n",
    "        \"param_columntransformer__num__simpleimputer__strategy\",\n",
    "        \"param_svc__gamma\",\n",
    "        \"mean_fit_time\",\n",
    "        \"rank_test_score\",\n",
    "    ]\n",
    "].set_index(\"rank_test_score\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many combinations in total?\n",
    "np.prod(list(map(len, param_grid.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problems with exhaustive grid search \n",
    "\n",
    "- Required number of models to evaluate grows exponentially with the dimensionally of the configuration space. \n",
    "- Example: Suppose you have\n",
    "    - 5 hyperparameters \n",
    "    - 10 different values for each hyperparameter\n",
    "    - You'll be evaluating $10^5=100,000$ models! That is you'll be calling `cross_validate` 100,000 times!\n",
    "- Exhaustive search may become infeasible fairly quickly. \n",
    "- Other options? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Randomized hyperparameter search\n",
    "\n",
    "- Randomized hyperparameter optimization \n",
    "    - [`sklearn.model_selection.RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "- Samples configurations at random until certain budget (e.g., time) is exhausted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid size: 144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'svc__gamma': array([1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01,\n",
       "        1.e+02, 1.e+03, 1.e+04, 1.e+05]),\n",
       " 'svc__C': array([1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01,\n",
       "        1.e+02, 1.e+03, 1.e+04, 1.e+05])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"svc__gamma\": 10.0 ** np.arange(-6, 6),\n",
    "    \"svc__C\": 10.0 ** np.arange(-6, 6),\n",
    "}\n",
    "print(\"Grid size: %d\" % (np.prod(list(map(len, param_grid.values())))))\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    pipe, param_distributions=param_grid, n_jobs=-1, n_iter=10, cv=5\n",
    ")\n",
    "random_search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_svc__gamma</th>\n",
       "      <th>param_svc__C</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.853852</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.612439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.849118</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.088907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.845406</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.887579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.783593</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2.034650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.778473</td>\n",
       "      <td>1</td>\n",
       "      <td>100000</td>\n",
       "      <td>7.923222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.757743</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.819518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.756847</td>\n",
       "      <td>10000</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>0.651702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.756847</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.710953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.756847</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.337574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.756847</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.709211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean_test_score param_svc__gamma param_svc__C  mean_fit_time\n",
       "rank_test_score                                                              \n",
       "1                       0.853852             0.01           10       0.612439\n",
       "2                       0.849118           0.0001        10000       1.088907\n",
       "3                       0.845406              0.1           10       0.887579\n",
       "4                       0.783593                1           10       2.034650\n",
       "5                       0.778473                1       100000       7.923222\n",
       "6                       0.757743               10        10000       1.819518\n",
       "7                       0.756847            10000        1e-06       0.651702\n",
       "7                       0.756847            1e-05         0.01       0.710953\n",
       "7                       0.756847           100000         0.01       1.337574\n",
       "7                       0.756847            1e-06          0.1       0.709211"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(random_search.cv_results_)[\n",
    "    [\n",
    "        \"mean_test_score\",\n",
    "        \"param_svc__gamma\",\n",
    "        \"param_svc__C\",\n",
    "        \"mean_fit_time\",\n",
    "        \"rank_test_score\",\n",
    "    ]\n",
    "].set_index(\"rank_test_score\").sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Advantages of `RandomizedSearchCV`\n",
    "\n",
    "- Faster compared to `GridSearchCV`.\n",
    "- Adding parameters that do not influence the performance does not affect efficiency.\n",
    "- In general, I recommend using `RandomizedSearchCV` rather than `GridSearchCV`.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Advantages of `RandomizedSearchCV`\n",
    "\n",
    "- Works better when some parameters are more important than others. \n",
    "\n",
    "![](images/randomsearch_bergstra.png)\n",
    "\n",
    "Source: [Bergstra and Bengio, Random Search for Hyper-Parameter Optimization, JMLR 2012](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf).\n",
    "- The yellow on the left shows how your scores are going to change when you vary the unimportant hyperparameter.\n",
    "- The green on the top shows how your scores are  going to change when you vary the important hyperparameter.\n",
    "- You don't know in advance which hyperparameters are important for your problem.\n",
    "- In the left figure, 6 of the 9 searches are useless because they are only varying the unimportant parameter.\n",
    "- In the right figure, all 9 searches are useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fancier methods (optional)\n",
    "- Both `GridSearchCV` and `RandomizedSearchCV` do each trial independently.\n",
    "- What if you could learn from your experience, e.g. learn that `max_depth=3` is bad?\n",
    "  - That could save time because you wouldn't try combinations involving `max_depth=3` in the future.\n",
    "- We can do this with `scikit-optimize`, which is a completely different package from `scikit-learn`\n",
    "- It uses a technique called \"model-based optimization\" and we'll specifically use \"Bayesian optimization\".\n",
    "  - In short, it uses machine learning to predict what hyperparameters will be good.\n",
    "  - Machine learning on machine learning!\n",
    "- This is an active research area and there are sophisticated packages for this. \n",
    "- It was Mike's [PhD thesis](https://dash.harvard.edu/bitstream/handle/1/17467236/GELBART-DISSERTATION-2015.pdf?sequence=4) topic. So you can bother him if want to know more about it :). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- If you want to run the following optional code, you'll have to install `scikit-optimize`\n",
    "\n",
    "`conda install -c conda-forge scikit-optimize`\n",
    "\n",
    "- `BayesSearchCV` uses the same interface as `GridSearchCV` and `RandomSearchCV`.\n",
    "- However, the way we specify the parameter distributions is slightly different.\n",
    "- Here, we can just give the bounds as tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(preprocessor, SVC())\n",
    "\n",
    "bayes_opt = BayesSearchCV(\n",
    "    pipe,\n",
    "    {\n",
    "        \"svc__C\": (0.1, 10),\n",
    "        \"columntransformer__num__simpleimputer__strategy\": (\"mean\", \"median\"),\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    random_state=123,\n",
    "    verbose=0,\n",
    "    refit=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "bayes_opt.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- It took a similar amount of time to the other methods.\n",
    "- In reality there is some extra computation to do the \"meta-ML\".\n",
    "- However, the overall time is dominated by the time of calling `fit` on the `SVC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('columntransformer__num__simpleimputer__strategy', 'mean'),\n",
       "             ('svc__C', 9.901973022704464)])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8523163552597901"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_opt.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Pros and cons of BayesOpt\n",
    "\n",
    "- Advantage: can find better hyperparameter values with fewer trials.\n",
    "- Disadvantage: requires installation.\n",
    "- Disadvantage: when number of trials is large (e.g. hundreds), the meta-ML can actually get too slow.\n",
    "- Disadvantage: harder to parallelize the search because each trial depends on the previous ones.\n",
    "  - Note `n_jobs` parameter for `GridSearchCV` and `RandomizedSearchCV`.  \n",
    "  - `BayesSearchCV` also has this parameter.\n",
    "  - It can definitely parallelize the folds.\n",
    "  - The search will be less effective if it parallelizes further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Questions for class discussion (hyperparameter optimization)\n",
    "\n",
    "- Suppose you have 10 hyperparameters, each with 4 possible values. If you run `GridSearchCV` with this parameter grid, how many cross-validation experiments it would carry out? \n",
    "- `GridSearchCV` exhaustively searches the grid and so it's guaranteed to give you the optimal hyperparameters for the given problem. \n",
    "- It is possible to get different hyperparameters in different runs of `RandomizedSearchCV`.\n",
    "- Suppose you have 10 hyperparameters and each takes 4 values. If you run `RandomizedSearchCV` with this parameter grid, how many cross-validation experiments it would carry out? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Optimization bias <a name=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Overfitting of the validation error \n",
    "\n",
    "- Why do we need to evaluate the model on the test set in the end?\n",
    "- Why not just use cross-validation on the whole dataset? \n",
    "- While carrying out hyperparameter optimization, we end up trying over many possibilities.  \n",
    "- If our dataset is small and if your validation set is hit too many times, we suffer from **optimization bias** or **overfitting the validation set**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Overfitting of the validation error \n",
    "\n",
    "Optimization bias of parameter learning:\n",
    "- During learning, we could search over tons of different decision trees.\n",
    "- So we can get \"lucky\" and find one with low training error by chance.\n",
    "    - \"Overfitting of the training error\".\n",
    "    \n",
    "Optimization bias of hyper-parameter learning:\n",
    "- Here, we might optimize the validation error over 100 values of `max_depth`.\n",
    "- One of the 100 trees might have low validation error by chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Example 1: Optimization bias (optional)\n",
    "\n",
    "Consider a multiple-choice (a,b,c,d) \"test\" with 10 questions:\n",
    "- If you choose answers randomly, expected grade is 25% (no bias).\n",
    "- If you fill out two tests randomly and pick the best, expected grade is 33%.\n",
    "    - Optimization bias of ~8%.\n",
    "- If you take the best among 10 random tests, expected grade is ~47%.\n",
    "- If you take the best among 100, expected grade is ~62%.\n",
    "- If you take the best among 1000, expected grade is ~73%.\n",
    "- If you take the best among 10000, expected grade is ~82%.\n",
    "    - You have so many \"chances\" that you expect to do well.\n",
    "    \n",
    "**But on new questions the \"random choice\" accuracy is still 25%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Code attribution: Thanks to Rodolfo! (optional)\n",
    "number_tests = [1, 2, 10, 100, 1000, 10000]\n",
    "for ntests in number_tests:\n",
    "    y = np.zeros(10000)\n",
    "    for i in range(10000):\n",
    "        y[i] = np.max(np.random.binomial(10.0, 0.25, ntests))\n",
    "    print(\n",
    "        \"The expected grade among the best of %d tests is : %0.2f\"\n",
    "        % (ntests, np.mean(y) / 10.0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Example 2: Optimization bias (optional)\n",
    "\n",
    "- If we instead used a 100-question test then:\n",
    "    - Expected grade from best over 1 randomly-filled test is 25%.\n",
    "    - Expected grade from best over 2 randomly-filled test is ~27%.\n",
    "    - Expected grade from best over 10 randomly-filled test is ~32%.\n",
    "    - Expected grade from best over 100 randomly-filled test is ~36%.\n",
    "    - Expected grade from best over 1000 randomly-filled test is ~40%.\n",
    "    - Expected grade from best over 10000 randomly-filled test is ~43%.\n",
    "\n",
    "- The optimization bias **grows with the number of things we try**.\n",
    "    - “Complexity” of the set of models we search over.\n",
    "- But, optimization bias **shrinks quickly with the number of examples**.\n",
    "    - But it’s still non-zero and growing if you over-use your validation set!    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Code attribution: Thanks to Rodolfo! (optional)\n",
    "number_tests = [1, 2, 10, 100, 1000, 10000]\n",
    "for ntests in number_tests:\n",
    "    y = np.zeros(10000)\n",
    "    for i in range(10000):\n",
    "        y[i] = np.max(np.random.binomial(100.0, 0.25, ntests))\n",
    "    print(\n",
    "        \"The expected grade among the best of %d tests is : %0.2f\"\n",
    "        % (ntests, np.mean(y) / 100.0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's examine effects of optimization on the adult income dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(adult_df_large, test_size=0.99, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325, 15)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "train_df_nan = train_df.replace(\"?\", np.NaN)\n",
    "test_df_nan = test_df.replace(\"?\", np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15087</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>119153</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11774</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>215477</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>30</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>182926</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23509</th>\n",
       "      <td>33</td>\n",
       "      <td>Private</td>\n",
       "      <td>124052</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>49</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>102359</td>\n",
       "      <td>9th</td>\n",
       "      <td>5</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2231</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  fnlwgt     education  education.num  \\\n",
       "15087   34    Private  119153          11th              7   \n",
       "11774   22    Private  215477  Some-college             10   \n",
       "1930    30  Local-gov  182926  Some-college             10   \n",
       "23509   33    Private  124052       HS-grad              9   \n",
       "197     49  Local-gov  102359           9th              5   \n",
       "\n",
       "           marital.status         occupation relationship   race   sex  \\\n",
       "15087  Married-civ-spouse   Transport-moving      Husband  White  Male   \n",
       "11774       Never-married   Transport-moving    Own-child  White  Male   \n",
       "1930   Married-civ-spouse    Protective-serv      Husband  White  Male   \n",
       "23509  Married-civ-spouse       Craft-repair      Husband  White  Male   \n",
       "197               Widowed  Handlers-cleaners    Unmarried  White  Male   \n",
       "\n",
       "       capital.gain  capital.loss  hours.per.week native.country income  \n",
       "15087             0             0              50  United-States  <=50K  \n",
       "11774             0             0              40  United-States  <=50K  \n",
       "1930          15024             0              40  United-States   >50K  \n",
       "23509             0             0              40  United-States  <=50K  \n",
       "197               0          2231              40  United-States   >50K  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_nan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<=50K    246\n",
       ">50K      79\n",
       "Name: income, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_nan[\"income\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Identify feature types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "numeric_features = [\"age\", \"fnlwgt\", \"capital.gain\", \"capital.loss\", \"hours.per.week\"]\n",
    "# I am removing eduction.num column\n",
    "categorical_features = [\n",
    "    \"workclass\",\n",
    "    \"marital.status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"sex\",\n",
    "    \"native.country\",\n",
    "]\n",
    "# I am removing 'race' column\n",
    "ordinal_features = [\"education\"]\n",
    "target = \"income\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_levels = [\n",
    "    \"Preschool\",\n",
    "    \"1st-4th\",\n",
    "    \"5th-6th\",\n",
    "    \"7th-8th\",\n",
    "    \"9th\",\n",
    "    \"10th\",\n",
    "    \"11th\",\n",
    "    \"12th\",\n",
    "    \"HS-grad\",\n",
    "    \"Prof-school\",\n",
    "    \"Assoc-voc\",\n",
    "    \"Assoc-acdm\",\n",
    "    \"Some-college\",\n",
    "    \"Bachelors\",\n",
    "    \"Masters\",\n",
    "    \"Doctorate\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df_nan.drop(columns=[target])\n",
    "y_train = train_df_nan[target]\n",
    "\n",
    "X_test = test_df_nan.drop(columns=[target])\n",
    "y_test = test_df_nan[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Define `ColumnTransformer` and a pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler())\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"),\n",
    ")\n",
    "\n",
    "ordinal_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "    OrdinalEncoder(\n",
    "        categories=[education_levels],\n",
    "        dtype=int,\n",
    "    ),\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "        (\"ordinal\", ordinal_transformer, ordinal_features),\n",
    "    ]\n",
    ")\n",
    "pipe = make_pipeline(preprocessor, SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid size: 900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'svc__gamma': array([1.e-20, 1.e-19, 1.e-18, 1.e-17, 1.e-16, 1.e-15, 1.e-14, 1.e-13,\n",
       "        1.e-12, 1.e-11, 1.e-10, 1.e-09, 1.e-08, 1.e-07, 1.e-06, 1.e-05,\n",
       "        1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03,\n",
       "        1.e+04, 1.e+05, 1.e+06, 1.e+07, 1.e+08, 1.e+09]),\n",
       " 'svc__C': array([1.e-20, 1.e-19, 1.e-18, 1.e-17, 1.e-16, 1.e-15, 1.e-14, 1.e-13,\n",
       "        1.e-12, 1.e-11, 1.e-10, 1.e-09, 1.e-08, 1.e-07, 1.e-06, 1.e-05,\n",
       "        1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03,\n",
       "        1.e+04, 1.e+05, 1.e+06, 1.e+07, 1.e+08, 1.e+09])}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"svc__gamma\": 10.0 ** np.arange(-20, 10),\n",
    "    \"svc__C\": 10.0 ** np.arange(-20, 10),\n",
    "}\n",
    "print(\"Grid size: %d\" % (np.prod(list(map(len, param_grid.values())))))\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    pipe, param_distributions=param_grid, n_jobs=-1, n_iter=900, cv=5\n",
    ")\n",
    "random_search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_svc__gamma</th>\n",
       "      <th>param_svc__C</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.852308</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.025669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.852308</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.027776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>1e+07</td>\n",
       "      <td>0.204596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.843077</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>1e+08</td>\n",
       "      <td>0.021219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean_test_score param_svc__gamma param_svc__C  mean_fit_time\n",
       "rank_test_score                                                              \n",
       "1                       0.852308            0.001         1000       0.025669\n",
       "1                       0.852308              0.1            1       0.024438\n",
       "3                       0.846154             0.01           10       0.027776\n",
       "3                       0.846154            1e-05        1e+07       0.204596\n",
       "5                       0.843077            1e-08        1e+08       0.021219"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(random_search.cv_results_)[\n",
    "    [\n",
    "        \"mean_test_score\",\n",
    "        \"param_svc__gamma\",\n",
    "        \"param_svc__C\",\n",
    "        \"mean_fit_time\",\n",
    "        \"rank_test_score\",\n",
    "    ]\n",
    "].set_index(\"rank_test_score\").sort_index().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Do we really believe that 0.85 is a good estimate of our test data?\n",
    "- Do we really believe that `gamma`=0.001 and C=1000 are the best hyperparameters? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- No, because our training data is quite small and so our validation splits in cross validation would be small. \n",
    "- No, because of the small dataset and the fact that we hit the small validation set 900 times and it's possible that we got lucky on the validation set! \n",
    "- Let's find out the test score with this best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8083198908053109"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- We can trust this test score because it's a huge test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Overfitting of the validation data\n",
    "\n",
    "<center>\n",
    "<img src='./images/optimization-bias.png' width=\"800\">\n",
    "</center>\n",
    "\n",
    "\n",
    "[Source](https://amueller.github.io/COMS4995-s20/slides/aml-03-supervised-learning/#20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Thus, not only can we not trust the cv scores, we also cannot trust cv's ability to choose of the best hyperparameters. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why do we need a test set? \n",
    "- We have a VERY optimistic cross-validation score.\n",
    "- This is why we need a test set.\n",
    "- The frustrating part is that if our dataset is small then our test set is also small :(. \n",
    "- But we don't have a lot of better alternatives, unfortunately, if we have a small dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Large datasets solves many of these problems\n",
    "- With infinite amounts of training data, overfitting would not be a problem and you could have your test score = your train score.\n",
    "    - Overfitting happens because you only see a bit of data and you learn patterns that are overly specific to your sample.\n",
    "    - If you saw \"all\" the data, then the notion of \"overly specific\" would not apply.\n",
    "- So, more data will make your test score better and robust. \n",
    "- What to do if your test score is much lower than your cross-validation score:\n",
    "    - Try simpler models and use the test set a couple of times - it's not the end of the world.\n",
    "    - Communicate this clearly when you report the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Questions for class discussion (optimization bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Would you trust the model?  \n",
    "\n",
    "- You have a dataset and you give me half of it. I build a model using all the data you have given me and I tell you that the model accuracy is 0.99. Would it classify the rest of the data with similar accuracy? \n",
    "\n",
    "1. Probably \n",
    "2. Probably not "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Would you trust the model?  \n",
    "\n",
    "- You have a dataset and you give me half of it. I build a model using 80% of the data given to me and report the accuracy of 0.95 on the remaining 20% of the data. Would it classify the rest of the data with similar accuracy? \n",
    "\n",
    "1. Probably \n",
    "2. Probably not "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Would you trust the model?  \n",
    "\n",
    "- You have a dataset and you give me 1/10th of it. The dataset given to me is rather small and so I split it into 96% train and 4% validation split. I carry out hyperparameter optimization using a single 4% validation split and report validation accuracy of 0.97. Would it classify the rest of the data with similar accuracy? \n",
    "\n",
    "1. Probably \n",
    "2. Probably not "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional readings and resources\n",
    "\n",
    "- [Preventing \"overfitting\" of cross-validation data](http://www.robotics.stanford.edu/~ang/papers/cv-final.pdf) by Andrew Ng"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:571]",
   "language": "python",
   "name": "conda-env-571-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
